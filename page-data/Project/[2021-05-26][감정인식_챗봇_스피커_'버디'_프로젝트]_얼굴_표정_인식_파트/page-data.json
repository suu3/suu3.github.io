{"componentChunkName":"component---src-templates-blog-post-js","path":"/Project/[2021-05-26][감정인식_챗봇_스피커_'버디'_프로젝트]_얼굴_표정_인식_파트/","result":{"data":{"site":{"siteMetadata":{"title":"Suu.Blog"}},"markdownRemark":{"id":"575a6884-bd2b-596c-96ed-b64123c0b316","excerpt":"0…","html":"<h2 id=\"01-프로젝트-설명\" style=\"position:relative;\"><a href=\"#01-%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8-%EC%84%A4%EB%AA%85\" aria-label=\"01 프로젝트 설명 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>01 프로젝트 설명</h2>\n<p>학교에서 <strong>딥러닝을 사용한 감정인식 챗봇 스피커 제작</strong> 을 주제로 프로젝트를 진행하고 있다. 스피커의 이름은 사용자에게 친숙하게 다가올 수 있게, 친구라는 뜻을 가진 '버디'라고 지었다.<br>\n버디의 주 기능은 <strong>사용자와 대화를 통해 우울감을 해소시켜주는 것</strong>이다.</p>\n<p>우울증은 무기력증을 동반하기때문에 환자가 직접 치료에 나서는 게 어렵고 환자가 주변 사람들에게 고민을 털어놓는 것 또한 어렵다.<br>\n사용자 가까이에 존재하면서 먼저 말을 걸어주는 기능을 탑재한, 위로나 의학적 안내를 건네는 인공지능 챗봇을 만들면 우울한 사람들에게 도움이 되지 않을까 하는 생각에서 프로젝트를 시작하게 되었다.</p>\n<p>우리 팀에서 내세우고 있는 프로젝트 특징은 크게 세가지이다.</p>\n<ol>\n<li>\n<p>사용자의 표정을 관찰하여 우울하다고 판단되면 스피커가 먼저 말을 건다.</p>\n</li>\n<li>\n<p>대화를 진행하면서 계속 사용자의 감정을 분석해 적절한 치료를 받을 수 있도록 안내한다.</p>\n</li>\n<li>\n<p>TTS 모델 타코트론을 사용하여 사용자에게 더욱 친숙하게 다가간다.</p>\n</li>\n</ol>\n<p>나는 이 세 가지 중 <strong>1번 - 얼굴 표정 감정 분석 파트</strong>를 맡았으며 해당 주제로 글을 쓰려고 한다.</p>\n<p>1번의 구체적인 플로우는 사용자와 가까운 곳에 배치된 스피커가 카메라를 사용해 사용자의 얼굴을 주기적으로 찍어서 표정의 감정을 분석하는 것이다. 메인보드로 라즈베리파이3 B+를 쓸 것이기 때문에, 카메라는 라즈베리파이 카메라 5MP를 사용했다.</p>\n<h2 id=\"02-얼굴-표정-분석---외부-서비스에서-제공해주는-face-api-사용하기\" style=\"position:relative;\"><a href=\"#02-%EC%96%BC%EA%B5%B4-%ED%91%9C%EC%A0%95-%EB%B6%84%EC%84%9D---%EC%99%B8%EB%B6%80-%EC%84%9C%EB%B9%84%EC%8A%A4%EC%97%90%EC%84%9C-%EC%A0%9C%EA%B3%B5%ED%95%B4%EC%A3%BC%EB%8A%94-face-api-%EC%82%AC%EC%9A%A9%ED%95%98%EA%B8%B0\" aria-label=\"02 얼굴 표정 분석   외부 서비스에서 제공해주는 face api 사용하기 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>02. 얼굴 표정 분석 - 외부 서비스에서 제공해주는 Face API 사용하기</h2>\n<p>얼굴 표정 분석을 위해 쓸 수 있는 방법으로는 Face API가 있다.<br>\n사용할 API는 <strong>Microsoft azure의 Cognitive Service - Face API</strong>이다.</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/34746d9eed148031f9708a79e465d2b2/3acf0/1.jpg\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 66.45569620253164%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAANABQDASIAAhEBAxEB/8QAFwABAQEBAAAAAAAAAAAAAAAAAAIBBf/EABQBAQAAAAAAAAAAAAAAAAAAAAD/2gAMAwEAAhADEAAAAe3tCVD/xAAZEAABBQAAAAAAAAAAAAAAAAAAARARMUH/2gAIAQEAAQUC0Sof/8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAwEBPwE//8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAgEBPwE//8QAFRABAQAAAAAAAAAAAAAAAAAAASD/2gAIAQEABj8Ca//EABoQAAMAAwEAAAAAAAAAAAAAAAABESExQWH/2gAIAQEAAT8hy0Id34P02Rb0igsI/9oADAMBAAIAAwAAABBjz//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQMBAT8QP//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8QP//EABsQAAIDAQEBAAAAAAAAAAAAAAERACFBgVFh/9oACAEBAAE/EASA6plyghnTjmY1mYZ6hEQtH7KADr0z/9k='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"Face API의 landmark\"\n        title=\"\"\n        src=\"/static/34746d9eed148031f9708a79e465d2b2/828fb/1.jpg\"\n        srcset=\"/static/34746d9eed148031f9708a79e465d2b2/ff44c/1.jpg 158w,\n/static/34746d9eed148031f9708a79e465d2b2/a6688/1.jpg 315w,\n/static/34746d9eed148031f9708a79e465d2b2/828fb/1.jpg 630w,\n/static/34746d9eed148031f9708a79e465d2b2/0ede0/1.jpg 945w,\n/static/34746d9eed148031f9708a79e465d2b2/3ac88/1.jpg 1260w,\n/static/34746d9eed148031f9708a79e465d2b2/3acf0/1.jpg 2000w\"\n        sizes=\"(max-width: 630px) 100vw, 630px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span>\n▲ Face API의 landmark</p>\n<p>Microsoft Azure의 Face API는 landmark로 27개를 사용한다고 한다. 감정분류는 anger, contempt, distgust, fear, happiness, neutral, sadness, surprise 8가지로 되어있다.<br>\n그 외 API가 어떤 구조로 되어있는지는 정보 공개가 되어있지 않은 것 같다.</p>\n<p><a href=\"https://azure.microsoft.com/ko-kr/services/cognitive-services/face/\"><strong>해당 사이트</strong></a>에서 Face API의 기능을 간단히 테스트 해볼 수 있다.</p>\n<p>이 프로젝트에서 사용한 건 표정분석만이지만, <strong>나이, 성별, 얼굴 식별 등의 기능</strong> 또한 제공한다고 한다.</p>\n<h3 id=\"api-사용을-위한-간단한-사전-절차\" style=\"position:relative;\"><a href=\"#api-%EC%82%AC%EC%9A%A9%EC%9D%84-%EC%9C%84%ED%95%9C-%EA%B0%84%EB%8B%A8%ED%95%9C-%EC%82%AC%EC%A0%84-%EC%A0%88%EC%B0%A8\" aria-label=\"api 사용을 위한 간단한 사전 절차 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>API 사용을 위한 간단한 사전 절차</h3>\n<ol>\n<li>\n<p>API를 사용하기 위해 먼저 Microsoft azure 가입을 해야한다. 참고로 azure에서는 student계정에 대해 12개월 간 무료로 100달러의 크레딧을 제공하고 있다. (나 또한 학생용 Azure을 사용 중이다.)</p>\n</li>\n<li>\n<p>Subscribe Key를 얻기 위해선 리소스를 만들어야 한다.</p>\n<ul>\n<li><a href=\"https://portal.azure.com/#home\"><strong>azure potal</strong></a>의 Cognitive Services에 들어간다.</li>\n<li><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/b50c59cfc306dc32b9eadbd16381261d/e8950/2.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 31.645569620253163%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAGCAYAAADDl76dAAAACXBIWXMAAAsTAAALEwEAmpwYAAABMUlEQVR42k2QS28UQQyE9///H26cIgJCucAFKcmSLEuyzBB2Z/rl7ra750MziQSWSmX5UbJr9+7rE++/DXz8IVwfElcPkc/HxHEqHKfKk1OeN9h/UG5+Ch8eI58OkevHwJexcn/J7FoVVDMrL63A0lmj90ZrDTPDWkNVX/M39P469y8WTCu7kIRwvvBye8d8v+fP5UzpC6qNEDPWO0HqxtY6rXWKGlIUawsh161ufSElYSdacfs983mGWhkfvpOaYaoMwwulZobxNyJCDB7nJpJkfo0jtVaeh5FpnliAUgq72ox4OBCHE/l0It7d4lNEayFJQs0IwRNCIGchpoiZ4ty82eD9jA9+e3oTzCUj3pPHkcU5onP4GDbf1gtWr9bldVhWwbVntolYM0QSVeubYOYvhJDNgGpmuVYAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"img.png\"\n        title=\"\"\n        src=\"/static/b50c59cfc306dc32b9eadbd16381261d/f058b/2.png\"\n        srcset=\"/static/b50c59cfc306dc32b9eadbd16381261d/c26ae/2.png 158w,\n/static/b50c59cfc306dc32b9eadbd16381261d/6bdcf/2.png 315w,\n/static/b50c59cfc306dc32b9eadbd16381261d/f058b/2.png 630w,\n/static/b50c59cfc306dc32b9eadbd16381261d/40601/2.png 945w,\n/static/b50c59cfc306dc32b9eadbd16381261d/78612/2.png 1260w,\n/static/b50c59cfc306dc32b9eadbd16381261d/e8950/2.png 2000w\"\n        sizes=\"(max-width: 630px) 100vw, 630px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span> face를 선택하면 된다.</li>\n</ul>\n</li>\n<li>\n<p>사진에서 구독 키와 엔드포인트를 확인할 수 있다.</p>\n<ul>\n<li><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/466815c97454698dfc2132adcdda8ff1/3acf0/3.jpg\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 28.48101265822785%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAGABQDASIAAhEBAxEB/8QAFgABAQEAAAAAAAAAAAAAAAAAAAEF/8QAFQEBAQAAAAAAAAAAAAAAAAAAAAH/2gAMAwEAAhADEAAAAd2iUH//xAAUEAEAAAAAAAAAAAAAAAAAAAAQ/9oACAEBAAEFAn//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/AT//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAECAQE/AT//xAAUEAEAAAAAAAAAAAAAAAAAAAAQ/9oACAEBAAY/An//xAAYEAEAAwEAAAAAAAAAAAAAAAAAAREhMf/aAAgBAQABPyF2MU//2gAMAwEAAgADAAAAEPwf/8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAwEBPxA//8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAgEBPxA//8QAGhAAAgIDAAAAAAAAAAAAAAAAAAERIUFR0f/aAAgBAQABPxB1yRUOk7E2Wf/Z'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"img.jpg\"\n        title=\"\"\n        src=\"/static/466815c97454698dfc2132adcdda8ff1/828fb/3.jpg\"\n        srcset=\"/static/466815c97454698dfc2132adcdda8ff1/ff44c/3.jpg 158w,\n/static/466815c97454698dfc2132adcdda8ff1/a6688/3.jpg 315w,\n/static/466815c97454698dfc2132adcdda8ff1/828fb/3.jpg 630w,\n/static/466815c97454698dfc2132adcdda8ff1/0ede0/3.jpg 945w,\n/static/466815c97454698dfc2132adcdda8ff1/3ac88/3.jpg 1260w,\n/static/466815c97454698dfc2132adcdda8ff1/3acf0/3.jpg 2000w\"\n        sizes=\"(max-width: 630px) 100vw, 630px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></li>\n</ul>\n</li>\n</ol>\n<h3 id=\"코드\" style=\"position:relative;\"><a href=\"#%EC%BD%94%EB%93%9C\" aria-label=\"코드 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>코드</h3>\n<p>설치해야할 패키지는 두가지이고, 코드는 다음과 같다.</p>\n<p>코드를 실행시키면 웹캠으로 사진을 일정시간 간격(일단은 약 2초 정도로 설정했다)으로 캡쳐해서 <strong>사진 저장-> 감정 출력-> 사진 삭제</strong>를 반복한다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">!pip install cognitive_face</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">!pip install opencv<span class=\"token operator\">-</span>python</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> cognitive_face <span class=\"token keyword\">as</span> CF\n<span class=\"token keyword\">import</span> cv2\nKEY <span class=\"token operator\">=</span> <span class=\"token string\">\"PASTE YOUR KEY\"</span>\nCF<span class=\"token punctuation\">.</span>Key<span class=\"token punctuation\">.</span><span class=\"token builtin\">set</span><span class=\"token punctuation\">(</span>KEY<span class=\"token punctuation\">)</span>\n\nBASE_URL <span class=\"token operator\">=</span> <span class=\"token string\">'https://koreacentral.api.cognitive.microsoft.com/face/v1.0/'</span>\nCF<span class=\"token punctuation\">.</span>BaseUrl<span class=\"token punctuation\">.</span><span class=\"token builtin\">set</span><span class=\"token punctuation\">(</span>BASE_URL<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\">#웹캠으로부터 사진을 캡쳐해서 분석하는 코드</span>\ncamera <span class=\"token operator\">=</span> cv2<span class=\"token punctuation\">.</span>VideoCapture<span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">while</span> <span class=\"token boolean\">True</span><span class=\"token punctuation\">:</span>\n    ret<span class=\"token punctuation\">,</span> image <span class=\"token operator\">=</span> camera<span class=\"token punctuation\">.</span>read<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">if</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">int</span><span class=\"token punctuation\">(</span>camera<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">%</span> <span class=\"token number\">60</span> <span class=\"token operator\">==</span> <span class=\"token number\">0</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'Saved image '</span> <span class=\"token operator\">+</span> <span class=\"token builtin\">str</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">int</span><span class=\"token punctuation\">(</span>camera<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n        cv2<span class=\"token punctuation\">.</span>imwrite<span class=\"token punctuation\">(</span><span class=\"token string\">\"emotions/frame.png\"</span><span class=\"token punctuation\">,</span> image<span class=\"token punctuation\">)</span>\n        img_url <span class=\"token operator\">=</span> <span class=\"token string\">'./emotions/frame.png'</span>\n        faces <span class=\"token operator\">=</span> CF<span class=\"token punctuation\">.</span>face<span class=\"token punctuation\">.</span>detect<span class=\"token punctuation\">(</span>img_url<span class=\"token punctuation\">,</span> <span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span> <span class=\"token boolean\">False</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"age, gender, emotion\"</span><span class=\"token punctuation\">)</span>\n\n        <span class=\"token keyword\">for</span> i <span class=\"token keyword\">in</span> faces<span class=\"token punctuation\">:</span>\n            sadness <span class=\"token operator\">=</span> i<span class=\"token punctuation\">[</span><span class=\"token string\">'faceAttributes'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span><span class=\"token string\">'emotion'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span><span class=\"token string\">'sadness'</span><span class=\"token punctuation\">]</span>\n            <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'sadness'</span><span class=\"token punctuation\">,</span> sadness<span class=\"token punctuation\">)</span>\n            <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>i<span class=\"token punctuation\">)</span>\n            <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\">#사진 삭제if os.path.isfile(img_url):</span>\n        \tos<span class=\"token punctuation\">.</span>remove<span class=\"token punctuation\">(</span>img_url<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># q를 누르면 종료된다if cv2.waitKey(1) &amp; 0xFF == ord('q'):</span>\n        <span class=\"token keyword\">break</span>\n\ncamera<span class=\"token punctuation\">.</span>release<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\ncv2<span class=\"token punctuation\">.</span>destroyAllWindows<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token triple-quoted-string string\">'''\n#사진 분석을 위해 사용하는 코드\nimg_url = 'PASTE URL'\nfaces = CF.face.detect(img_url, True, False, \"age, gender, emotion\")\n\nfor i in faces:\n    sadness = i['faceAttributes']['emotion']['sadness']\n    print('sadness:', sadness)\n    print(i)\n    print()\n\n#얼굴 주변 사각형 그리기\nimport requests\nfrom io import BytesIO\nfrom PIL import Image, ImageDraw\n\ndef getRectangle(faceDictionary):\n    rect = faceDictionary['faceRectangle']\n    left = rect['left']\n    top = rect['top']\n    right = left + rect['width']\n    bottom = top + rect['height']\n    return ((left, top), (right, bottom))\n\n#http~ url일 때\n#response = requests.get(img_url)\n#img = Image.open(BytesIO(response.content))\n\n#로컬 이미지일 때\nimg = Image.open(img_url)\ndraw = ImageDraw.Draw(img)\nfor face in faces:\n    draw.rectangle(getRectangle(face), outline='red')\n\nimg.show()\n'''</span>\n</code></pre></div>\n<p>KEY에는 위의 구독키를 넣고, BASE_URL에는 위치에 맞는 URL을 넣으면 된다.(<a href=\"https://westus.dev.cognitive.microsoft.com/docs/services\"><strong>여기</strong></a>에서 URL을 찾을 수 있다.)<br>\n나는 한국 중부 URL을 넣었다.</p>\n<h3 id=\"테스트\" style=\"position:relative;\"><a href=\"#%ED%85%8C%EC%8A%A4%ED%8A%B8\" aria-label=\"테스트 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>테스트</h3>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/ba701d4b4d348f58c56eb5b5deae8057/e8950/4.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 39.24050632911392%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAICAYAAAD5nd/tAAAACXBIWXMAAAsSAAALEgHS3X78AAACUklEQVR42jWJ6UvTAQBAf/QHRGlaEem8naxIM4/WjIZZatNJc+YxzcSrQPNoWSrOe87KaUJUZGIt+2KUWoqZkKlLm86yAiGQ6EMHrlCT6Qf3AqEHDx48YXrSgipBjWRfMEdkEfQ/H+TLwness5+YsUwzZ53h/dxH4lLTuVhURoWugaioGPz8Awg8GIImI5vMrPNEnzpNa9sthNamZnzc3JH4SkiWhVKvLeHD5wXeTs0wNvoGi3mcyXdTBEfIyckrQqE8g9N2Zw54++C8dRtiSRBKVTr7A6VUVTciZGvScHN1JsjXi5bcFDqb6rHOzjNutjA4MMDoq2EmJswci4qlsLiCk9HxZMRE06YtRimTEhZymBRNDmHSSGrrDQjy8FD27HAi2M+LruJcOq/peTk8xtDwa/r7ehkdGcE8YeZErJLs/GIaCgoxXshjsKURbXoqygQ1SSmZhEmPU1NnQAgM8Md9pwsysSc6RQQpihie9g1h6u6h4959TF0mep/1IZXJOSqPRl9USGmymo7SAmLlkcQoVCQkajgULkdXo0fwE4nY5eyCWCQiwMMDH08xl8tqqK69jq6qjva2u/Q8eYHrbjcEQSBfrSYrPo6r584i8vBGELZsvr3uYi5pKxFuGtupvlKFoaGRurp6KsvLedR1B/OUFYvFyvz8Al+//UDfbCRXk8Ftg4GWG0YePzBRUFSCQpmAKjGJtPQsuh52IwCs/V1h+c9vVlZWWF1dZWlpabPX19f5j2Njg6VfP1lcXMRms7Fos7G8vIzdbt90bc2Ow+HgH9dkj8gn4VxoAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"img.png\"\n        title=\"\"\n        src=\"/static/ba701d4b4d348f58c56eb5b5deae8057/f058b/4.png\"\n        srcset=\"/static/ba701d4b4d348f58c56eb5b5deae8057/c26ae/4.png 158w,\n/static/ba701d4b4d348f58c56eb5b5deae8057/6bdcf/4.png 315w,\n/static/ba701d4b4d348f58c56eb5b5deae8057/f058b/4.png 630w,\n/static/ba701d4b4d348f58c56eb5b5deae8057/40601/4.png 945w,\n/static/ba701d4b4d348f58c56eb5b5deae8057/78612/4.png 1260w,\n/static/ba701d4b4d348f58c56eb5b5deae8057/e8950/4.png 2000w\"\n        sizes=\"(max-width: 630px) 100vw, 630px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></p>\n<p>드라마 사진으로 테스트 했을 때, 위와 같은 결과가 나왔다.\n(슬픈 표정ㅡ sadness: 0.924 / 무표정ㅡ sadness: 0.002, neutral: 0.998)</p>\n<p>'울 것 같은 얼굴'도 잘 인식하는 모습이다.</p>\n<p>실제론 사진이 아니라 카메라 캡쳐방식으로 동작할 것이므로, 얼굴을 주기적으로 찍는 코드도 한번 실행 시켜보았다.<br>\n(테스트 할만한 적절한 영상을 찾기가 어려워서... 그냥 직접 웹캠을 키고 슬픈 영상 찾아 보면서 테스트를 해봤다 ㅎ)</p>\n<p>총 71프레임이었고, matplotlib으로 나타냈을 때 다음과 같았다.</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/95e482ffdb42a58099a84cf4a52eb9a5/e8950/5.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 68.35443037974683%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAOCAYAAAAvxDzwAAAACXBIWXMAAAsTAAALEwEAmpwYAAABa0lEQVR42pWUi06DMBSG9/7vp4mLMRGnG5eW0ntLy29OgTm3RUeTcoDyfzlXdgAQQoBSCtbah7cxpmxnbdHmnAmFHV2ccxjHEY+saZotNwHKzxp7od/FGNE0DVJKDwJn4mlw6E3AtUPFQ+/9Bg9nYC39fSDddF23OeROBTDtb4FSypLcrcDBRtSDuwVWVQWt9WagdGPJ4w2QSs45/xM4XeTuX+B1UUg4LcLLPaaMlKdfwKP4Aaa0AKmpqShr2+RFQWJaJiQwHbA/yQLRS+9RDx64gRvzfQ9zSuhMxDszRVhxi7dWo1Ue+1rh0Ft8cIuXk0KrAo6Dw2uj8PQlYaw9O1TahnUduNRopcWBaTx/cgzGQxiHXjv4EKFcRC0MhPFoBgvlApyPECZgkApp9ZByRrMphEAIHn3PEbxHzxli8OCsKxFwtjwv7+ncWgM5CCglzwXcrYWg4SZLo0jrnqVziqh8RzbnEur6YyDgNz1OSe5IAWuTAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"img.png\"\n        title=\"\"\n        src=\"/static/95e482ffdb42a58099a84cf4a52eb9a5/f058b/5.png\"\n        srcset=\"/static/95e482ffdb42a58099a84cf4a52eb9a5/c26ae/5.png 158w,\n/static/95e482ffdb42a58099a84cf4a52eb9a5/6bdcf/5.png 315w,\n/static/95e482ffdb42a58099a84cf4a52eb9a5/f058b/5.png 630w,\n/static/95e482ffdb42a58099a84cf4a52eb9a5/40601/5.png 945w,\n/static/95e482ffdb42a58099a84cf4a52eb9a5/78612/5.png 1260w,\n/static/95e482ffdb42a58099a84cf4a52eb9a5/e8950/5.png 2000w\"\n        sizes=\"(max-width: 630px) 100vw, 630px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></p>\n<p>▲ x축 = 프레임 번호(시간순으로 봐도 무방), y축 = sadness</p>\n<p>무표정->눈물까지 가는 데 얼마 걸리지 않은 모습이다.\n사람이 봤을 때 '슬퍼 보이는' 사진은 40부터였는데, 그래프 상에서는 차이를 확인할 수 없었다. 대신 60(=얼굴이 일그러지면서 울음이 터지는 사진)에서 반짝 하고 최고치 (0.932)를 찍었다.</p>\n<p>웹캠으로 테스트 해본 결과, 사진으로 테스트 해봤을 때 생각하지 못했던 변수가 몇가지 있었다.<br>\n<strong>순간 캡쳐라 흔들린 사진이 찍힌다는 점, 카메라 화질에 영향을 받는 점</strong> 등의 이유로 <strong>빨개진 눈 같은 특징을 가진 '울 것 같은' 얼굴이나 눈물은 인식할 수 없었고</strong>, 대신 확실하게 <strong>입꼬리가 내려가거나 얼굴이 찡그려진 순간은 포착</strong>한다는 걸 확인해 볼 수 있었다.</p>\n<h2 id=\"02-얼굴-표정-분석---캐글-데이터로-표정분석하기\" style=\"position:relative;\"><a href=\"#02-%EC%96%BC%EA%B5%B4-%ED%91%9C%EC%A0%95-%EB%B6%84%EC%84%9D---%EC%BA%90%EA%B8%80-%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%A1%9C-%ED%91%9C%EC%A0%95%EB%B6%84%EC%84%9D%ED%95%98%EA%B8%B0\" aria-label=\"02 얼굴 표정 분석   캐글 데이터로 표정분석하기 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>02. 얼굴 표정 분석 - 캐글 데이터로 표정분석하기</h2>\n<p>표정 분석방법으로는<strong>캐글 데이터를 활용해서 직접 학습시키는 방법</strong>도 있다.<br>\n1번의 Face API는 (무료 크레딧으로 해결할 수 있지만) 아무래도 비용이 나갈 수 있기 때문에 직접 학습시키는 방법도 생각해볼 수 있다.</p>\n<p>표정 분석은 얼굴 인식 - 표정 분류 두 단계로 이루어진다. \n위의 Face API가 기본적으로 얼굴인식부터 표정분류까지 학습된 모델을 다 제공한다면, 여기서는 하나하나 구성해야 한다.</p>\n<h3 id=\"얼굴-인식\" style=\"position:relative;\"><a href=\"#%EC%96%BC%EA%B5%B4-%EC%9D%B8%EC%8B%9D\" aria-label=\"얼굴 인식 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>얼굴 인식</h3>\n<p>먼저, 얼굴 인식을 위해서 opencv에서 제공하고 있는 cascade 기반으로 미리 학습된 정면 얼굴 데이터(haarcascade_frontalface_default.xml)를 사용할 수 있다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">pip install opencv<span class=\"token operator\">-</span>python</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> cv2\nface_detection <span class=\"token operator\">=</span> cv2<span class=\"token punctuation\">.</span>CascadeClassifier<span class=\"token punctuation\">(</span><span class=\"token string\">'haarcascade_frontalface_default.xml'</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p>혹은 dlib 라이브러리를 이용할 수도 있다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">pip install dlib</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> dlib\nface_detector <span class=\"token operator\">=</span> dlib<span class=\"token punctuation\">.</span>get_frontal_face_detector<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p>이런식으로 사용할 수 있다.<br>\n만약에 dlib 설치 과정에서 오류가 발생 한다면, Cmake GUI를 이용하거나 <code class=\"language-text\">pip install cmake</code>로 해결할 수 있다.</p>\n<p>그 다음으로, 얼굴 인식 성능을 높이려면 측면·명암 등의 조건을 고려했을 때에도 얼굴을 인식할 수 있도록 얼굴에 존재하는 랜드마크를 이용해야한다. 이 때에도 dlib 라이브러리를 이용해 68개의 얼굴 랜드마크로 학습된 모델을 사용할 수 있다. (<a href=\"http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2\"><strong>dlib landmarks</strong></a>)</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> dlib\npredictor <span class=\"token operator\">=</span> dlib<span class=\"token punctuation\">.</span>shape_predictor<span class=\"token punctuation\">(</span><span class=\"token string\">'shape_predictor_68_face_landmarks.dat'</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/a358b63edf6a5c6cc1d190b966bb88c1/e8950/6.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 66.45569620253164%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAANCAIAAAAmMtkJAAAACXBIWXMAAAsTAAALEwEAmpwYAAABIklEQVR42oWSyY7DIAxA8/+f1XuPqdRDeukiVUUlNgYbHMhoYIRGXd8Jg59sMMP6BDMTETOXUlSViADAe19KecgcHmIiut/v1lpjjIg454wxAGCMiTHmnN/KzKyq3vtxHI/HIyKKyDRNu92ulCIiMca3soio6rqurUNE9N73kJk/yaqaUurZABBC6GGMsZ2+lpdlaaVandPpdLlcuuCc+yTnnFupnPP1eh3Hcb/f32631i0RLcvy5bVVNcY4TdNms9lut4fDQStE9GVUOWciypU2pLZGxIc5/cql8uz366WUELFNoT1ezx/WV7TLi0ioPP+tP5mIrLVzBRHneQYA55z33lYAoG1ipSeHEIaUEjPLP2JFRM7nszGmtdDhioiklH4AVCT2qp2I4koAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"img.png\"\n        title=\"\"\n        src=\"/static/a358b63edf6a5c6cc1d190b966bb88c1/f058b/6.png\"\n        srcset=\"/static/a358b63edf6a5c6cc1d190b966bb88c1/c26ae/6.png 158w,\n/static/a358b63edf6a5c6cc1d190b966bb88c1/6bdcf/6.png 315w,\n/static/a358b63edf6a5c6cc1d190b966bb88c1/f058b/6.png 630w,\n/static/a358b63edf6a5c6cc1d190b966bb88c1/40601/6.png 945w,\n/static/a358b63edf6a5c6cc1d190b966bb88c1/78612/6.png 1260w,\n/static/a358b63edf6a5c6cc1d190b966bb88c1/e8950/6.png 2000w\"\n        sizes=\"(max-width: 630px) 100vw, 630px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></p>\n<h3 id=\"표정-분류\" style=\"position:relative;\"><a href=\"#%ED%91%9C%EC%A0%95-%EB%B6%84%EB%A5%98\" aria-label=\"표정 분류 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>표정 분류</h3>\n<p>본격적으로 표정분류를 하기위해 사용할 데이터는 <a href=\"https://www.kaggle.com/msambare/fer2013\"><strong>캐글 FER-2013 Faces atabase</strong></a>이다.</p>\n<p>28,709개의 example이 있으며, 표정 분류는 Angry, Disgust, Fear, Happy, Sad, Surprise, Neutral 로 되어있다.</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/2f098ee772a774a3f90504639584249c/e8950/7.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 17.088607594936708%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAADCAYAAACTWi8uAAAACXBIWXMAAAsTAAALEwEAmpwYAAAAv0lEQVR42h2OvQpAABhFvbAnQCmbQmQxSCKDDIqB5LckFvJTShlM3uLKt9zhdm/nMM/zIMsyVFUFwzAgyzL6vkdRFBiGAWVZom1bjOOIOI6hKAokSYJt27AsC8dx4L5v2m7bBuYPlmXhui54noeu62iaBr7vwzRNOI4DQRDAcRyCIIDneRBFEaqqQtM0gp/nSdCu68C874s0TbHvO9nUdU3UaZowzzMdwjBEkiRk8Xd5ntM2iiKCX9eFdV2xLAs+FAS6cNvuqsUAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"img.png\"\n        title=\"\"\n        src=\"/static/2f098ee772a774a3f90504639584249c/f058b/7.png\"\n        srcset=\"/static/2f098ee772a774a3f90504639584249c/c26ae/7.png 158w,\n/static/2f098ee772a774a3f90504639584249c/6bdcf/7.png 315w,\n/static/2f098ee772a774a3f90504639584249c/f058b/7.png 630w,\n/static/2f098ee772a774a3f90504639584249c/40601/7.png 945w,\n/static/2f098ee772a774a3f90504639584249c/78612/7.png 1260w,\n/static/2f098ee772a774a3f90504639584249c/e8950/7.png 2000w\"\n        sizes=\"(max-width: 630px) 100vw, 630px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span>\n▲ Angry, Disgust, Fear, Happy, Neutral, Sad, Surprise</p>\n<p>대충 각 분류에서 하나씩 출력해보자면 이런 이미지의 데이터셋인데, 벌써부터 Surprise나 Angry에서 오분류의 느낌이 느껴진다 ^^;..</p>\n<h3 id=\"사진-표정-분석-테스트\" style=\"position:relative;\"><a href=\"#%EC%82%AC%EC%A7%84-%ED%91%9C%EC%A0%95-%EB%B6%84%EC%84%9D-%ED%85%8C%EC%8A%A4%ED%8A%B8\" aria-label=\"사진 표정 분석 테스트 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>사진 표정 분석 테스트</h3>\n<p>위의 데이터를 사용해서 Keras로 CNN을 구현하여 모델을 학습시켰다.</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/4eca6af66ae6636be82834ea69c59a76/e8950/8.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 84.17721518987341%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAARCAYAAADdRIy+AAAACXBIWXMAAAsTAAALEwEAmpwYAAAB5klEQVR42pXUV08rUQwE4P3//w2JInpJoXcCIYWSQd8eWeSBh3tXspw9tueMx950w2Fyf588PSVnZ8nVVfLykv5ZrZp9fiZfX81/f/+eM+9izHs3GCSnp8neXgN8fGwX3N0174KdneT4ONnYaP7hIbm9bX48bnH18rvRKDk8TPiDg+T8PJnPk/f3ZDZLXl9/z9n1daKrm5uW8/ycbG42MPk9IGaSTk4SjOsCbPijo+TiogHy8gF8fDRAEi0WzTrUJdAQfaDaLpZvb00SAFjJByyHbsD291v7NO4BsahWLi9bgWIgdSFN5TgXF1suG0PnpOkZClZr2GHJqpiJe68zsrgIAKaI6FBXnWKim6ZCeikqbXgt0Q6IvJIIQ4DixbhvWZsSsSwJAAAuKWqdal1q96bTxtQ+9hrSRgtAsfWbHm6TqABreTqRJ2ZYhlYXTSZra4MN/TCp/QNUUy4N5ZJBXIxmJLFmZtG3XKsCVCF9JCliABWsa1crVYA6ktsPBRhzu0+IB6IFpqWtrXaOxfqwANF5e7vlqesGg1WGw1W/vPTDwtQUA1RMIwVA6iLnPMYG5b0BDltL2AHStg99d7dN83+fbjyYZTRa9tOjI63qS9ASrWpAf5lYWT/lxXSSuV9/POv/e/9qP5yfFkW/NDvXAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"img.png\"\n        title=\"\"\n        src=\"/static/4eca6af66ae6636be82834ea69c59a76/f058b/8.png\"\n        srcset=\"/static/4eca6af66ae6636be82834ea69c59a76/c26ae/8.png 158w,\n/static/4eca6af66ae6636be82834ea69c59a76/6bdcf/8.png 315w,\n/static/4eca6af66ae6636be82834ea69c59a76/f058b/8.png 630w,\n/static/4eca6af66ae6636be82834ea69c59a76/40601/8.png 945w,\n/static/4eca6af66ae6636be82834ea69c59a76/78612/8.png 1260w,\n/static/4eca6af66ae6636be82834ea69c59a76/e8950/8.png 2000w\"\n        sizes=\"(max-width: 630px) 100vw, 630px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span>\n<span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/f1e2c1eaf0039aa2ef9bcd2ff137f90f/e8950/9.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 114.55696202531647%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAXCAYAAAALHW+jAAAACXBIWXMAAAsTAAALEwEAmpwYAAAD4UlEQVR42k2U2U8UTRTF+2808U1xiXs00bjExF0RF1BEUfZxgAwRRomoaASNz/og0aDDCKIQYAABR8av2xm6+vfl9LXBh5uqrrp1zj13aW9l5QeFQoHC3AKzM/OslnwiB85FrK1Ff1dHGEaxRZHuiNdKJcQ5x+/fJcIwJAh8vNVfCxR/zlNaXeRXcZ6VlTmWl+ZYXCzwY3GWleUl5gvTFItLLC7MUS6XiaIKYViJ13K5wvR0hampCqVSGa+tbY36ekd3t6O315HNhmSza3R0hKRSjnQ6JJPZ2Dc0RKTTEe3tEalURG1tRFVVxKZN8PZtCa+z0/H4MQwPQWsrHD4MR4/C6dNw+TK0tNh5W6utN2/CjRtw9y7cuWMmn2vX4Nu3PwYoh/p6Ozx40ADv3YOXL2Fw0ICPHzeSS5egttbA29shlYLmZrh+HfL5AK+nx8UMurh/Hxoboa0Nbt+2KG7dgjNnYN8+A+zthTdv4OFDOHsWTp2ytboaPn8O8AYHXRxNQ4OBKMorV2wv4Na/UnWfSBapVB07Bnv2wPnzRjAzE+ANDbn48e7ddinGjg6LVvnRnaIUSU2NAUliU9MGsPZK2devAV5Li4sdFbYeyenRI5OmCLZvNyLlTSSKOiFStHpz9aoBTkwEeP39LmaQg0wOdXUWjfYi0oN0Gp48MVAVbts22L/fwKVIFhelsdHFkZw7twGmSwGoUEl7KEJFISJVVIVSKrq6YGDAZI+MBHg1NY6dO60YT5/CixcmS5GpqqqeQCSvu9siFKGIlJ5/iWLJmhBJVaVliubCBcubTFE8e2Zy9Vh3MqVBPSl/EUnNly8B3oMHLpYg56RaqqKAtIpEEetcqdmyxaYpk7HG7++3FKz3YV2diydBTOp8mSSp70SiVAhUKnSeTInItQpMxdm6FT58CPD6+lws59Urm0lNxIED1o8qUBKhiASgSAWiVXnUvc5FNDkZ4HV1ufhhIluyVEE5PX9uFVRx9u6FI0csbwKTIqVEfgJWTsfGAjz9liQnaRNJlZzkh5H0pMDUVn198Pq1Nf+JE3Z+8qSlJpcL8IaH3XrIeqx8CkCmtlDedK8iKRIp0V7+aq1Dh+xMSmZnA7yBAft97dhB3I8adI2dTL0nZtnFiyZXhFKgvCp/yWzrfHz8j0lOZEminHt6oLPT8llVZf2ox9msTYaI9EZ5E1B1dRTvx8d9vEzGrf+ytKpp5STTdzLLIlIDS7Y6YfNm2LULmpp1HsWpef9+GS+f/4+PH31GRzcsn/f5/t1nctLn0yefXM5nZMTutI6N+bx75zMx4TM9VWRqap5crsjo6Cz/A8K6ymiXnWQiAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"img.png\"\n        title=\"\"\n        src=\"/static/f1e2c1eaf0039aa2ef9bcd2ff137f90f/f058b/9.png\"\n        srcset=\"/static/f1e2c1eaf0039aa2ef9bcd2ff137f90f/c26ae/9.png 158w,\n/static/f1e2c1eaf0039aa2ef9bcd2ff137f90f/6bdcf/9.png 315w,\n/static/f1e2c1eaf0039aa2ef9bcd2ff137f90f/f058b/9.png 630w,\n/static/f1e2c1eaf0039aa2ef9bcd2ff137f90f/40601/9.png 945w,\n/static/f1e2c1eaf0039aa2ef9bcd2ff137f90f/78612/9.png 1260w,\n/static/f1e2c1eaf0039aa2ef9bcd2ff137f90f/e8950/9.png 2000w\"\n        sizes=\"(max-width: 630px) 100vw, 630px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span>\n▲ 모델 요약 및 학습 진행 화면(4시간 소요)</p>\n<p>Face API를 테스트하기 위해 썼던 드라마 사진으로 똑같이 테스트를 해보았다.</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/f618dc0ba7d6b2657230ce3031aa2fa4/e8950/10.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 72.15189873417721%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAOCAYAAAAvxDzwAAAACXBIWXMAAAsSAAALEgHS3X78AAAD4UlEQVR42iXR+W/TBRjH8e+foBy7ytqusKNb2croxmCDjeFGhtphgoPoD25RMcQhDhSYaJCgoBxzh8o4lOGBgOtK+/2mdkd3tuvartfWtZMKCxp/QNkmQsw6f3ib1R+e5HnySV75JI8QmQwRjc5gvGVkS8lWCguLKSjYiEaTzebiTVxqvxjPw9MzRO78Rjhyj0AwjNcbIODzExj3EPT5mApOcDd6F8HndOGyj6HfvgOVIoM0pRpV2lqUimySklJIV8rp6PiG6V9+Jxi6h88/icvtx+2ZwOPy4BweYnxsjMD4OHciEYRIMMRXX1xgnVpNgTYfrUZLZroGlSqH2qpt7NtRygvV1YQiM0xMzTC+BHp8cXTUPopj0Mb4mJOg18PP4RBCdDrKgTf2kqmUk6fOIj9jDXlpaezaVMjImUYM79Vz+JWX8I75mIrcx+2bwOH0MDrqYXhwiMHeHlyjDrxuN9NLDScDQSpLislUKshIU5CnlJOuSKW6RMfVQ3U06Ms58W4DQc8EE5NRXN4gdocnPt1WKz+JZob7bbgcDsKTkwjirZtolArUKiXylCQ0qTLkyQlUarOxnD3OsRefpeWjD/G6grjdIZwuPyN2F/0DI5iMXUi3Ddh6uhmzO5ieCiOcbDyKKjGB7NVLYCJZKUnIVi7n9Ksv4+tox/zx+4gdl+nrHsDWO0TfoIu+fjtWay+S6TYWUaS/twen3U4kNIWwZ6ceZVICWUo5aauSyZGlkJqwjPOv1XDt9d006ss4+vabSCYLomhF6h7CJFkxmUREsxlJFOm1WhkdHiYcCiM8v70SecJKMuSrUMqSyUmVoUpJ4MTuCtprnmNvRTEbinQYb3VhkroxSj0Yb5vp7DRgMHRiNHQhmUUG+/rxe/0IFVvL42D6qhTkyYlxMH3F09SXaWmr07N1bQaK5U9xsbkNk2WA72+aufL1ddraLtL8WSvnz7XQdK6VlqbPufHDjwjby8uRLV+GMjmR1MQV8Q8vtV2/Ro5cJiN9tZpctZbaun20fPktxz44w8FDxznwViMHG45w+J1GTp08S3NTO10GEaF2TzWK5FQ0mTnkqnPRaYvYqCuhqnQb67TF6NaXosvfTOH6Io40nuLT8+2c/qSJ1tYLXLl8levf3UCS+hka8RMIRhEa9tezQVdGeWkVZZsr2VJcwZZNZdTs3Ma6vLVkZmSTk6VB/0weR/fv4tr1mxgkGyapF1GyYLF0Y7M5GYyDdxAeP37M3Nw883N/MT83H9/nZmd59GiW2dk/ePDgT+z2h/x6f56Ffx7y5MnfxBYXWViIsbCwQCwWIxb7/15c/Jf/ABVM1T7srCWiAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"img.png\"\n        title=\"\"\n        src=\"/static/f618dc0ba7d6b2657230ce3031aa2fa4/f058b/10.png\"\n        srcset=\"/static/f618dc0ba7d6b2657230ce3031aa2fa4/c26ae/10.png 158w,\n/static/f618dc0ba7d6b2657230ce3031aa2fa4/6bdcf/10.png 315w,\n/static/f618dc0ba7d6b2657230ce3031aa2fa4/f058b/10.png 630w,\n/static/f618dc0ba7d6b2657230ce3031aa2fa4/40601/10.png 945w,\n/static/f618dc0ba7d6b2657230ce3031aa2fa4/78612/10.png 1260w,\n/static/f618dc0ba7d6b2657230ce3031aa2fa4/e8950/10.png 2000w\"\n        sizes=\"(max-width: 630px) 100vw, 630px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span>\n<span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/eae40cdbdd7cdfa82c0ed489033846d7/e8950/13.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 74.0506329113924%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAPCAYAAADkmO9VAAAACXBIWXMAAAsSAAALEgHS3X78AAADtklEQVR42oWS20+aBxiHv67Vgii4aqebzlqUitW2COIR+DgJIsJQzgh4oJ4mCmzigdI6m24JqdnBRF1styxp3OYWe7FlV7vf/7Glf4O7fBbpsmRXfZP37s2T55ffKzin51BrdEwGp0hnN1leW+fDTJ7F5Rx6/SD11xuou95AfX0DdfWNDButBCPTeHxh3J4ADpcPi92Nyexk0GBFMAWiKNVdBCMzLKXzzC/lWFrJ09dvpKZGjlxeS3VNLTXyWqpkcuSKa9idXjy+GA6XH+uIF4Poon/Ijq5PRDBNhFCpu5hNrZDObLOaLRBPLnCjtY36dxppfq+ZDmUbnco23m1sRiKtpvuOjlB0jvEPIjhck1jsHoZNTvoGLwy9k7SrOllO51nNbrO++QkWm4sbTS3cbFEyKYrYtTqcWi0alRqZREZLa1sZ6PPHGfOEGBmdwGi+sLQhDDvddHfdYzVXKO/61i53e/RIKq/iNBhZT8RZmvASd41i7OlBIa2ivf0W4dgMk8EkHl+0bGmyjP0LtLvo0w+R+bjISmaLdHYbh9ODSaPj+YN1zr4ocfKkyP5GjuJMHOPtTkSThWgiVQZ6J2KMugOINjcDw3aEIbMdw7CFdGarXMj8YobnOw/Zn5vj0+k4f5wcc1ra5az0mIONDEaNlgl/lNjUDIFQ/D+g2Tb+GjhgEBHFEe4v5ogkFsgurvD9owL5YJgHU1HOPtvhxUdZft17wuy4C522n2TyPqFIgslArBzZOeZHtLpfl9LbP4jV6mL2/hr+aIq9/Aa/H3xOwO4kaLXwQzHPaS7LV+l5/G4vsfA08ak5AqGLuFP/K6X8NhpdH716A2abm95BEYfZxm9H++zl1vD36znKZ/ll7zHFZARVuxqHbRSvL4Q/mMTnT5QLuYg7aBhBqzchdHR2c6VSiqSqhgppNVel1Xz9qMhhYQubRkPWP8GzzRyF1RWqFHVckchQXLtOq7KDO5o+DKITgziKfsDCPe0wQmd3Txkiq6nlcqWM27fU/Py0xEIkRioxzZxZZDc1S7HwgIamFqTVCmSKt5HI5GURpeo2Q0YHPb1Guu8NIHjCs7zf3o1MUY8gCKQ8Ho42N+hSqclvFEgHQ2zMp3j4aIeGxqbyzaW3riBcrkAQLlFRKUGpusPN9rs0tXQgnPz0ktKXh6RzW8RiSb59usezUolYNM7x8Tf8ePqSw4PvODx6QTQ2i9XuwDHqxuEaY8Thwm4fIRiOkZiZJzI1jcAb5vxv+PMvePUKzs954/wD+ONcipnMQnQAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"img.png\"\n        title=\"\"\n        src=\"/static/eae40cdbdd7cdfa82c0ed489033846d7/f058b/13.png\"\n        srcset=\"/static/eae40cdbdd7cdfa82c0ed489033846d7/c26ae/13.png 158w,\n/static/eae40cdbdd7cdfa82c0ed489033846d7/6bdcf/13.png 315w,\n/static/eae40cdbdd7cdfa82c0ed489033846d7/f058b/13.png 630w,\n/static/eae40cdbdd7cdfa82c0ed489033846d7/40601/13.png 945w,\n/static/eae40cdbdd7cdfa82c0ed489033846d7/78612/13.png 1260w,\n/static/eae40cdbdd7cdfa82c0ed489033846d7/e8950/13.png 2000w\"\n        sizes=\"(max-width: 630px) 100vw, 630px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></p>\n<p>각각 sadness와 neutral이 0.9를 넘는 높은 수치로 나왔던 Face API와 비교했을 때, 슬픈 표정의 예시로 사용한 왼쪽 사진의 감정을 fear로 다르게 인식한 것을 확인할 수 있었다.</p>\n<p>이 데이터셋을 사용한 여러가지 모델을 찾아보았을 때, 대략 정확도가 50%~70%정도로 나오는걸 알 수 있었다. 때문에 일부 데이터가 오분류 되어 있는게 정확도가 낮은 원인이 아닐까 생각된다.<br>\n같은 데이터셋을 사용한 Kaggle 챌린지 best score의 상위권에 랭크한 코드 역시 test accuracy가 50% 정도로 나온 걸 확인할 수 있었다.</p>\n<h3 id=\"실시간-영상-분석-테스트\" style=\"position:relative;\"><a href=\"#%EC%8B%A4%EC%8B%9C%EA%B0%84-%EC%98%81%EC%83%81-%EB%B6%84%EC%84%9D-%ED%85%8C%EC%8A%A4%ED%8A%B8\" aria-label=\"실시간 영상 분석 테스트 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>실시간 영상 분석 테스트</h3>\n<p>openCV를 활용하여 실시간 영상 표정 분석을 하는 코드도 실행을 시켜보았다. <a href=\"https://m.blog.naver.com/roboholic84/221633210887\"><strong>다음 링크</strong></a>의 코드를 참고했다.</p>\n<p>같은 캐글 데이터를 사용하지만 다른 구조를 갖고있는 모델을 사용했다.</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/6c0fb4b2a48d9ac9bb783074d13bd8d6/e8950/11.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 136.0759493670886%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAbCAYAAAB836/YAAAACXBIWXMAAAsTAAALEwEAmpwYAAACcElEQVR42pXVCW8iMQwF4Pn/v64SFFTaQqH05D5aoFdWnyWPWER3YaQoGU/8/J7tZKpy5Pn+/i4vLy9lMpmU0WhUBoNBub+/jzXb09NT+fr6OuZaqmPGz8/PcFqv12WxWJSrq6sY8/k8bI+Pj7HnZEDP6+tr6ff74dztdsvl5WV5fn4Om2A/Pz+nA358fIQzR2B3d3dlOByWm5ubCMBuz8mAossXEADX19el2WzGmk2wsxjKj6JsNpvImaIAXS6XYfsvQ9FyeFRwPB6X2WwWAzNy811+z6pytg4n8/v7ezBO9my/PZUN8pXyjLe3twAxttttsMo9BrvZPsNae7FXWDCm9JSM0XQ6rfPX6XRiZpMCcypJ5jVgRsVC85q1izzKV6/Xi7VCCGq/90MSiIXk3W4XjmiTh4kG1iK+qSrp+32aDPcBa4ZAgXEUWSNfXFzUDEkEAlSA1WpVHz9s2WtAElHN9nD45e/h4SGkAxTILICR39nsyRYDXomclVYAMwezAE4FZ6AYcCQXkUwThtbYh2QGp4AzhgBcBlkgAbKhzd7dPtaZFmmAE4CQOe87ArUZIHZUKAAnDBUsi8H+V1HI5syRBCwnk2nYBAIO0F578l48PFmRQ5t8BCJn2JEOrNVqlXa7HWwws8+3ZCZIDt/JrrKv8ijlccv7T64Uy7tZf97e3tY5y+NowKmO3YUeDDEiT86yndh8k/eTbpsEzCOHmWPYaDQil1iy7/9T9q+/fzLMnKZ8+cPS+8k/qUPJ+tPIwsmVVjpbMifSyDSTrGWwU5izbmw9RapiaHQ/eTdQ/gLOkpyAJGcbyRtQskn2/hvgH/cUH8K4bk1MAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"img.png\"\n        title=\"\"\n        src=\"/static/6c0fb4b2a48d9ac9bb783074d13bd8d6/f058b/11.png\"\n        srcset=\"/static/6c0fb4b2a48d9ac9bb783074d13bd8d6/c26ae/11.png 158w,\n/static/6c0fb4b2a48d9ac9bb783074d13bd8d6/6bdcf/11.png 315w,\n/static/6c0fb4b2a48d9ac9bb783074d13bd8d6/f058b/11.png 630w,\n/static/6c0fb4b2a48d9ac9bb783074d13bd8d6/40601/11.png 945w,\n/static/6c0fb4b2a48d9ac9bb783074d13bd8d6/78612/11.png 1260w,\n/static/6c0fb4b2a48d9ac9bb783074d13bd8d6/e8950/11.png 2000w\"\n        sizes=\"(max-width: 630px) 100vw, 630px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span>\n<span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/fad64162140a6b0e4ac326e97c8f631b/e8950/12.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 55.69620253164557%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAYAAAB/Ca1DAAAACXBIWXMAAAsSAAALEgHS3X78AAACL0lEQVR42p3TS0hUURjA8evgbKbdbBRXElrqImiVOzchGAShCyWhfJQRNBOBoUKBPTAowgE1lKKFYJgVZFCMpqRiD1MpHGzS1Oud1Hk4D+ft3Jl7/zF3oVHR68C3+M6B33c+zncE/nGpqvrbc0FOJtnaChIJR0ilUsiyjJxIIMsJYrEY8e1tttN5MvlXBQW3N8C0bQHJ5WXdF2Ru3kZv730673TQ1d3FoHUE2xcJdyBIxOtFnJ9nWRSx2+1a2Gw2XC7Xzu0FXzCMXdzA6Y8QkFXGhqxcaajHfKqOa62XGZ54w+KqixAwY7FQajSSW1TEHoMBvV6PIAiYzWYNTHcoBEJRVpw+NkNxQimVZwP9XD9/hvYmEzeaLzL+fpZVp590w486OijM38eh4mIMBgM6nU4DTSbTLugPR1lY87DhD+KJxrBNjWO93cLTtkZ6bl5l5O0MS2se4sBoezsHs7PZW1CgQfrMzJ/Bza0w059FFtfdjL77yOO+h3zqu0X3hVpqjlcz+HKMD0sOfCl4ZbFQkpNDbn4+uowMMn8FOjbcPJ+Ywjo5Q21DI+XlNVwyneVYWSn7Cw/Q0trG0OtZRF+QyZ4e7ubl8aikhP6sLA4bjRrY3NS0Cy5JX3kyPEbnvQdUVp6kru4cVdX1VFRUUXbkKCfqTzPwYoS5xWVS0QhRh4O400lCkvBIEiuiiN/v3x2b9FMrikIymdQqpBQFVVW0PS3XQvnjQO+A//NTfozvwW/aNtNGrFGjlgAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"img.png\"\n        title=\"\"\n        src=\"/static/fad64162140a6b0e4ac326e97c8f631b/f058b/12.png\"\n        srcset=\"/static/fad64162140a6b0e4ac326e97c8f631b/c26ae/12.png 158w,\n/static/fad64162140a6b0e4ac326e97c8f631b/6bdcf/12.png 315w,\n/static/fad64162140a6b0e4ac326e97c8f631b/f058b/12.png 630w,\n/static/fad64162140a6b0e4ac326e97c8f631b/40601/12.png 945w,\n/static/fad64162140a6b0e4ac326e97c8f631b/78612/12.png 1260w,\n/static/fad64162140a6b0e4ac326e97c8f631b/e8950/12.png 2000w\"\n        sizes=\"(max-width: 630px) 100vw, 630px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></p>\n<p>▲ 신경망 구조 및 실행화면(얼굴을 한껏 찌푸린 상태)</p>\n<p>역시나 웹캠을 키고 직접 테스트해본 결과, 얼굴 일그러짐에 따른 Sadness는 잘 인식했던 Face API에 반해 Neutral로 오판하는 것을 확인할 수 있었다.</p>\n<h2 id=\"04-마무리\" style=\"position:relative;\"><a href=\"#04-%EB%A7%88%EB%AC%B4%EB%A6%AC\" aria-label=\"04 마무리 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>04 마무리</h2>\n<p>지금까지 프로젝트 간단 설명, Microsoft Azure Face API, 캐글데이터를 사용한 표정인식 방법을 알아보았다.</p>\n<p>정리하자면 Face API와, 캐글 데이터를 사용하여 직접 학습시킨 모델을 각각 테스트 한 다음 비교해본 결과 <strong>최종적으로 Microsoft azure의 Face API</strong>가 우리 팀의 프로젝트의 표정 분석 파트의 기술로 채택되었다.</p>\n<p>Face API의 경우에는 API라 얼굴 인식 자체의 정확도는 높일 수 없지만 감정 추출 주기를 조정하거나, 만약 단순 분류가 아니라 수치를 이용한다면 그 기준점 등을 조정해보면서 얼굴을 더 잘 인식할 수 있는 방법을 찾아볼 예정이다.</p>\n<h2 id=\"05-참고자료\" style=\"position:relative;\"><a href=\"#05-%EC%B0%B8%EA%B3%A0%EC%9E%90%EB%A3%8C\" aria-label=\"05 참고자료 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>05 참고자료</h2>\n<ul>\n<li><a href=\"https://www.kaggle.com/dencho143/face-emotion-classification-with-mlp-2-barykin\">https://www.kaggle.com/dencho143/face-emotion-classification-with-mlp-2-barykin</a></li>\n<li><a href=\"https://github.com/sunsmiling/facial-emotion-detector\">https://github.com/sunsmiling/facial-emotion-detector</a></li>\n<li><a href=\"https://github.com/SeoJinHyuk14/facialExpression\">https://github.com/SeoJinHyuk14/facialExpression</a></li>\n<li><a href=\"https://m.blog.naver.com/roboholic84/221633210887\">https://m.blog.naver.com/roboholic84/221633210887</a></li>\n<li><a href=\"https://electronicprogrammers.com/44\">https://electronicprogrammers.com/44</a></li>\n<li><a href=\"https://github.com/dinuduke/Facial-Emotion-Recognition\">https://github.com/dinuduke/Facial-Emotion-Recognition</a></li>\n</ul>","tableOfContents":"<ul>\n<li>\n<p><a href=\"#01-%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8-%EC%84%A4%EB%AA%85\">01 프로젝트 설명</a></p>\n</li>\n<li>\n<p><a href=\"#02-%EC%96%BC%EA%B5%B4-%ED%91%9C%EC%A0%95-%EB%B6%84%EC%84%9D---%EC%99%B8%EB%B6%80-%EC%84%9C%EB%B9%84%EC%8A%A4%EC%97%90%EC%84%9C-%EC%A0%9C%EA%B3%B5%ED%95%B4%EC%A3%BC%EB%8A%94-face-api-%EC%82%AC%EC%9A%A9%ED%95%98%EA%B8%B0\">02. 얼굴 표정 분석 - 외부 서비스에서 제공해주는 Face API 사용하기</a></p>\n<ul>\n<li><a href=\"#api-%EC%82%AC%EC%9A%A9%EC%9D%84-%EC%9C%84%ED%95%9C-%EA%B0%84%EB%8B%A8%ED%95%9C-%EC%82%AC%EC%A0%84-%EC%A0%88%EC%B0%A8\">API 사용을 위한 간단한 사전 절차</a></li>\n<li><a href=\"#%EC%BD%94%EB%93%9C\">코드</a></li>\n<li><a href=\"#%ED%85%8C%EC%8A%A4%ED%8A%B8\">테스트</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#02-%EC%96%BC%EA%B5%B4-%ED%91%9C%EC%A0%95-%EB%B6%84%EC%84%9D---%EC%BA%90%EA%B8%80-%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%A1%9C-%ED%91%9C%EC%A0%95%EB%B6%84%EC%84%9D%ED%95%98%EA%B8%B0\">02. 얼굴 표정 분석 - 캐글 데이터로 표정분석하기</a></p>\n<ul>\n<li><a href=\"#%EC%96%BC%EA%B5%B4-%EC%9D%B8%EC%8B%9D\">얼굴 인식</a></li>\n<li><a href=\"#%ED%91%9C%EC%A0%95-%EB%B6%84%EB%A5%98\">표정 분류</a></li>\n<li><a href=\"#%EC%82%AC%EC%A7%84-%ED%91%9C%EC%A0%95-%EB%B6%84%EC%84%9D-%ED%85%8C%EC%8A%A4%ED%8A%B8\">사진 표정 분석 테스트</a></li>\n<li><a href=\"#%EC%8B%A4%EC%8B%9C%EA%B0%84-%EC%98%81%EC%83%81-%EB%B6%84%EC%84%9D-%ED%85%8C%EC%8A%A4%ED%8A%B8\">실시간 영상 분석 테스트</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#04-%EB%A7%88%EB%AC%B4%EB%A6%AC\">04 마무리</a></p>\n</li>\n<li>\n<p><a href=\"#05-%EC%B0%B8%EA%B3%A0%EC%9E%90%EB%A3%8C\">05 참고자료</a></p>\n</li>\n</ul>","frontmatter":{"title":"[감정인식 챗봇 스피커 '버디' 프로젝트] 얼굴 표정 인식 파트","date":"2021.05.26","description":"[감정인식 챗봇 스피커 '버디' 프로젝트]의 얼굴 표정 인식 파트 구현 내용","category":"Project","tag":["project","딥러닝"]}},"previous":null,"next":{"fields":{"slug":"/Project/[2021-11-11][패션_정보_웹]_쇼핑몰_크롤링/"},"frontmatter":{"title":"[패션 정보 웹 프로젝트] 쇼핑몰 크롤링"}}},"pageContext":{"id":"575a6884-bd2b-596c-96ed-b64123c0b316","previousPostId":null,"nextPostId":"e638a735-355e-5159-9e23-1de785ca3a54"}},"staticQueryHashes":["2841359383"],"slicesMap":{}}