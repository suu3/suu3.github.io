{"componentChunkName":"component---src-templates-blog-post-js","path":"/Project/[2021-05-26][감정인식_챗봇_스피커_'버디'_프로젝트]_얼굴_표정_인식_파트/","result":{"data":{"site":{"siteMetadata":{"title":"Suu.Blog"}},"markdownRemark":{"id":"04d510f2-b08c-5af6-a737-260d9f24c926","excerpt":"0…","html":"<h2 id=\"01-프로젝트-설명\" style=\"position:relative;\"><a href=\"#01-%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8-%EC%84%A4%EB%AA%85\" aria-label=\"01 프로젝트 설명 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>01 프로젝트 설명</h2>\n<p>학교에서 <strong>딥러닝을 사용한 감정인식 챗봇 스피커 제작</strong> 을 주제로 프로젝트를 진행하고 있다. 스피커의 이름은 사용자에게 친숙하게 다가올 수 있게, 친구라는 뜻을 가진 '버디'라고 지었다.<br>\n버디의 주 기능은 <strong>사용자와 대화를 통해 우울감을 해소시켜주는 것</strong>이다.</p>\n<p>우울증은 무기력증을 동반하기때문에 환자가 직접 치료에 나서는 게 어렵고 환자가 주변 사람들에게 고민을 털어놓는 것 또한 어렵다.<br>\n사용자 가까이에 존재하면서 먼저 말을 걸어주는 기능을 탑재한, 위로나 의학적 안내를 건네는 인공지능 챗봇을 만들면 우울한 사람들에게 도움이 되지 않을까 하는 생각에서 프로젝트를 시작하게 되었다.</p>\n<p>우리 팀에서 내세우고 있는 프로젝트 특징은 크게 세가지이다.</p>\n<ol>\n<li>\n<p>사용자의 표정을 관찰하여 우울하다고 판단되면 스피커가 먼저 말을 건다.</p>\n</li>\n<li>\n<p>대화를 진행하면서 계속 사용자의 감정을 분석해 적절한 치료를 받을 수 있도록 안내한다.</p>\n</li>\n<li>\n<p>TTS 모델 타코트론을 사용하여 사용자에게 더욱 친숙하게 다가간다.</p>\n</li>\n</ol>\n<p>나는 이 세 가지 중 <strong>1번 - 얼굴 표정 감정 분석 파트</strong>를 맡았으며 해당 주제로 글을 쓰려고 한다.</p>\n<p>1번의 구체적인 플로우는 사용자와 가까운 곳에 배치된 스피커가 카메라를 사용해 사용자의 얼굴을 주기적으로 찍어서 표정의 감정을 분석하는 것이다. 메인보드로 라즈베리파이3 B+를 쓸 것이기 때문에, 카메라는 라즈베리파이 카메라 5MP를 사용했다.</p>\n<h2 id=\"02-얼굴-표정-분석---외부-서비스에서-제공해주는-face-api-사용하기\" style=\"position:relative;\"><a href=\"#02-%EC%96%BC%EA%B5%B4-%ED%91%9C%EC%A0%95-%EB%B6%84%EC%84%9D---%EC%99%B8%EB%B6%80-%EC%84%9C%EB%B9%84%EC%8A%A4%EC%97%90%EC%84%9C-%EC%A0%9C%EA%B3%B5%ED%95%B4%EC%A3%BC%EB%8A%94-face-api-%EC%82%AC%EC%9A%A9%ED%95%98%EA%B8%B0\" aria-label=\"02 얼굴 표정 분석   외부 서비스에서 제공해주는 face api 사용하기 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>02. 얼굴 표정 분석 - 외부 서비스에서 제공해주는 Face API 사용하기</h2>\n<p>얼굴 표정 분석을 위해 쓸 수 있는 방법으로는 Face API가 있다.<br>\n사용할 API는 <strong>Microsoft azure의 Cognitive Service - Face API</strong>이다.</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/34746d9eed148031f9708a79e465d2b2/3acf0/1.jpg\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 66.45569620253164%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAANABQDASIAAhEBAxEB/8QAFwABAQEBAAAAAAAAAAAAAAAAAAIBBf/EABQBAQAAAAAAAAAAAAAAAAAAAAD/2gAMAwEAAhADEAAAAe3tCVD/xAAZEAABBQAAAAAAAAAAAAAAAAAAARARMUH/2gAIAQEAAQUC0Sof/8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAwEBPwE//8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAgEBPwE//8QAFRABAQAAAAAAAAAAAAAAAAAAASD/2gAIAQEABj8Ca//EABoQAAMAAwEAAAAAAAAAAAAAAAABESExQWH/2gAIAQEAAT8hy0Id34P02Rb0igsI/9oADAMBAAIAAwAAABBjz//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQMBAT8QP//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8QP//EABsQAAIDAQEBAAAAAAAAAAAAAAERACFBgVFh/9oACAEBAAE/EASA6plyghnTjmY1mYZ6hEQtH7KADr0z/9k='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"Face API의 landmark\"\n        title=\"\"\n        src=\"/static/34746d9eed148031f9708a79e465d2b2/828fb/1.jpg\"\n        srcset=\"/static/34746d9eed148031f9708a79e465d2b2/ff44c/1.jpg 158w,\n/static/34746d9eed148031f9708a79e465d2b2/a6688/1.jpg 315w,\n/static/34746d9eed148031f9708a79e465d2b2/828fb/1.jpg 630w,\n/static/34746d9eed148031f9708a79e465d2b2/0ede0/1.jpg 945w,\n/static/34746d9eed148031f9708a79e465d2b2/3ac88/1.jpg 1260w,\n/static/34746d9eed148031f9708a79e465d2b2/3acf0/1.jpg 2000w\"\n        sizes=\"(max-width: 630px) 100vw, 630px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span>\n▲ Face API의 landmark</p>\n<p>Microsoft Azure의 Face API는 landmark로 27개를 사용한다고 한다. 감정분류는 anger, contempt, distgust, fear, happiness, neutral, sadness, surprise 8가지로 되어있다.<br>\n그 외 API가 어떤 구조로 되어있는지는 정보 공개가 되어있지 않은 것 같다.</p>\n<p><a href=\"https://azure.microsoft.com/ko-kr/services/cognitive-services/face/\"><strong>해당 사이트</strong></a>에서 Face API의 기능을 간단히 테스트 해볼 수 있다.</p>\n<p>이 프로젝트에서 사용한 건 표정분석만이지만, <strong>나이, 성별, 얼굴 식별 등의 기능</strong> 또한 제공한다고 한다.</p>\n<h3 id=\"api-사용을-위한-간단한-사전-절차\" style=\"position:relative;\"><a href=\"#api-%EC%82%AC%EC%9A%A9%EC%9D%84-%EC%9C%84%ED%95%9C-%EA%B0%84%EB%8B%A8%ED%95%9C-%EC%82%AC%EC%A0%84-%EC%A0%88%EC%B0%A8\" aria-label=\"api 사용을 위한 간단한 사전 절차 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>API 사용을 위한 간단한 사전 절차</h3>\n<ol>\n<li>\n<p>API를 사용하기 위해 먼저 Microsoft azure 가입을 해야한다. 참고로 azure에서는 student계정에 대해 12개월 간 무료로 100달러의 크레딧을 제공하고 있다. (나 또한 학생용 Azure을 사용 중이다.)</p>\n</li>\n<li>\n<p>Subscribe Key를 얻기 위해선 리소스를 만들어야 한다.</p>\n<ul>\n<li><a href=\"https://portal.azure.com/#home\"><strong>azure potal</strong></a>의 Cognitive Services에 들어간다.</li>\n<li><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/b50c59cfc306dc32b9eadbd16381261d/e8950/2.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 31.645569620253163%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAGCAYAAADDl76dAAAACXBIWXMAAAsTAAALEwEAmpwYAAABMUlEQVR42k2Qy07DMBBF8///w44VoiDEBjZIfdCW0paE0jaJHb+TwzgFgaWrsTxzH57i6nnL9UvJ3Zthsu64WWoeNh2bsxN4tk1gNyL+Q+Dx3XC70tyvNZOV4qnyzE+WInlDCJZch+Rg6Mmn7xMpJWKMRKkhhMv9B31/mfs7AzF4CtUZ1PHEYTqjni/4Oh1x/SACCaUtUYjK+LHG1ItJjwsR48QgDSjrx/conE60CiOqzWJBfazBe6rlK12SFJKoLA84bymrT4wxaNXSNGc6Y/moKhn37MqKc32WfOCco/BC1us1utxj93v0bErbaYJ3QuwI8j0lQkoprBVR6cUYRLge19C2Na30+RW0zmLaFiuOQ9OgBa1W495ygryrTM7DJgvmnphkkShhjJh6+eVF0PINhJDNgEBMpnYAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"img.png\"\n        title=\"\"\n        src=\"/static/b50c59cfc306dc32b9eadbd16381261d/f058b/2.png\"\n        srcset=\"/static/b50c59cfc306dc32b9eadbd16381261d/c26ae/2.png 158w,\n/static/b50c59cfc306dc32b9eadbd16381261d/6bdcf/2.png 315w,\n/static/b50c59cfc306dc32b9eadbd16381261d/f058b/2.png 630w,\n/static/b50c59cfc306dc32b9eadbd16381261d/40601/2.png 945w,\n/static/b50c59cfc306dc32b9eadbd16381261d/78612/2.png 1260w,\n/static/b50c59cfc306dc32b9eadbd16381261d/e8950/2.png 2000w\"\n        sizes=\"(max-width: 630px) 100vw, 630px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span> face를 선택하면 된다.</li>\n</ul>\n</li>\n<li>\n<p>사진에서 구독 키와 엔드포인트를 확인할 수 있다.</p>\n<ul>\n<li><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/466815c97454698dfc2132adcdda8ff1/3acf0/3.jpg\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 28.48101265822785%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAGABQDASIAAhEBAxEB/8QAFgABAQEAAAAAAAAAAAAAAAAAAAEF/8QAFQEBAQAAAAAAAAAAAAAAAAAAAAH/2gAMAwEAAhADEAAAAd2iUH//xAAUEAEAAAAAAAAAAAAAAAAAAAAQ/9oACAEBAAEFAn//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/AT//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAECAQE/AT//xAAUEAEAAAAAAAAAAAAAAAAAAAAQ/9oACAEBAAY/An//xAAYEAEAAwEAAAAAAAAAAAAAAAAAAREhMf/aAAgBAQABPyF2MU//2gAMAwEAAgADAAAAEPwf/8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAwEBPxA//8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAgEBPxA//8QAGhAAAgIDAAAAAAAAAAAAAAAAAAERIUFR0f/aAAgBAQABPxB1yRUOk7E2Wf/Z'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"img.jpg\"\n        title=\"\"\n        src=\"/static/466815c97454698dfc2132adcdda8ff1/828fb/3.jpg\"\n        srcset=\"/static/466815c97454698dfc2132adcdda8ff1/ff44c/3.jpg 158w,\n/static/466815c97454698dfc2132adcdda8ff1/a6688/3.jpg 315w,\n/static/466815c97454698dfc2132adcdda8ff1/828fb/3.jpg 630w,\n/static/466815c97454698dfc2132adcdda8ff1/0ede0/3.jpg 945w,\n/static/466815c97454698dfc2132adcdda8ff1/3ac88/3.jpg 1260w,\n/static/466815c97454698dfc2132adcdda8ff1/3acf0/3.jpg 2000w\"\n        sizes=\"(max-width: 630px) 100vw, 630px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></li>\n</ul>\n</li>\n</ol>\n<h3 id=\"코드\" style=\"position:relative;\"><a href=\"#%EC%BD%94%EB%93%9C\" aria-label=\"코드 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>코드</h3>\n<p>설치해야할 패키지는 두가지이고, 코드는 다음과 같다.</p>\n<p>코드를 실행시키면 웹캠으로 사진을 일정시간 간격(일단은 약 2초 정도로 설정했다)으로 캡쳐해서 <strong>사진 저장-> 감정 출력-> 사진 삭제</strong>를 반복한다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">!pip install cognitive_face</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">!pip install opencv<span class=\"token operator\">-</span>python</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> cognitive_face <span class=\"token keyword\">as</span> CF\n<span class=\"token keyword\">import</span> cv2\nKEY <span class=\"token operator\">=</span> <span class=\"token string\">\"PASTE YOUR KEY\"</span>\nCF<span class=\"token punctuation\">.</span>Key<span class=\"token punctuation\">.</span><span class=\"token builtin\">set</span><span class=\"token punctuation\">(</span>KEY<span class=\"token punctuation\">)</span>\n\nBASE_URL <span class=\"token operator\">=</span> <span class=\"token string\">'https://koreacentral.api.cognitive.microsoft.com/face/v1.0/'</span>\nCF<span class=\"token punctuation\">.</span>BaseUrl<span class=\"token punctuation\">.</span><span class=\"token builtin\">set</span><span class=\"token punctuation\">(</span>BASE_URL<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\">#웹캠으로부터 사진을 캡쳐해서 분석하는 코드</span>\ncamera <span class=\"token operator\">=</span> cv2<span class=\"token punctuation\">.</span>VideoCapture<span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">while</span> <span class=\"token boolean\">True</span><span class=\"token punctuation\">:</span>\n    ret<span class=\"token punctuation\">,</span> image <span class=\"token operator\">=</span> camera<span class=\"token punctuation\">.</span>read<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">if</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">int</span><span class=\"token punctuation\">(</span>camera<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">%</span> <span class=\"token number\">60</span> <span class=\"token operator\">==</span> <span class=\"token number\">0</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'Saved image '</span> <span class=\"token operator\">+</span> <span class=\"token builtin\">str</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">int</span><span class=\"token punctuation\">(</span>camera<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n        cv2<span class=\"token punctuation\">.</span>imwrite<span class=\"token punctuation\">(</span><span class=\"token string\">\"emotions/frame.png\"</span><span class=\"token punctuation\">,</span> image<span class=\"token punctuation\">)</span>\n        img_url <span class=\"token operator\">=</span> <span class=\"token string\">'./emotions/frame.png'</span>\n        faces <span class=\"token operator\">=</span> CF<span class=\"token punctuation\">.</span>face<span class=\"token punctuation\">.</span>detect<span class=\"token punctuation\">(</span>img_url<span class=\"token punctuation\">,</span> <span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span> <span class=\"token boolean\">False</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"age, gender, emotion\"</span><span class=\"token punctuation\">)</span>\n\n        <span class=\"token keyword\">for</span> i <span class=\"token keyword\">in</span> faces<span class=\"token punctuation\">:</span>\n            sadness <span class=\"token operator\">=</span> i<span class=\"token punctuation\">[</span><span class=\"token string\">'faceAttributes'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span><span class=\"token string\">'emotion'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span><span class=\"token string\">'sadness'</span><span class=\"token punctuation\">]</span>\n            <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'sadness'</span><span class=\"token punctuation\">,</span> sadness<span class=\"token punctuation\">)</span>\n            <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>i<span class=\"token punctuation\">)</span>\n            <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\">#사진 삭제if os.path.isfile(img_url):</span>\n        \tos<span class=\"token punctuation\">.</span>remove<span class=\"token punctuation\">(</span>img_url<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># q를 누르면 종료된다if cv2.waitKey(1) &amp; 0xFF == ord('q'):</span>\n        <span class=\"token keyword\">break</span>\n\ncamera<span class=\"token punctuation\">.</span>release<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\ncv2<span class=\"token punctuation\">.</span>destroyAllWindows<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token triple-quoted-string string\">'''\n#사진 분석을 위해 사용하는 코드\nimg_url = 'PASTE URL'\nfaces = CF.face.detect(img_url, True, False, \"age, gender, emotion\")\n\nfor i in faces:\n    sadness = i['faceAttributes']['emotion']['sadness']\n    print('sadness:', sadness)\n    print(i)\n    print()\n\n#얼굴 주변 사각형 그리기\nimport requests\nfrom io import BytesIO\nfrom PIL import Image, ImageDraw\n\ndef getRectangle(faceDictionary):\n    rect = faceDictionary['faceRectangle']\n    left = rect['left']\n    top = rect['top']\n    right = left + rect['width']\n    bottom = top + rect['height']\n    return ((left, top), (right, bottom))\n\n#http~ url일 때\n#response = requests.get(img_url)\n#img = Image.open(BytesIO(response.content))\n\n#로컬 이미지일 때\nimg = Image.open(img_url)\ndraw = ImageDraw.Draw(img)\nfor face in faces:\n    draw.rectangle(getRectangle(face), outline='red')\n\nimg.show()\n'''</span>\n</code></pre></div>\n<p>KEY에는 위의 구독키를 넣고, BASE_URL에는 위치에 맞는 URL을 넣으면 된다.(<a href=\"https://westus.dev.cognitive.microsoft.com/docs/services\"><strong>여기</strong></a>에서 URL을 찾을 수 있다.)<br>\n나는 한국 중부 URL을 넣었다.</p>\n<h3 id=\"테스트\" style=\"position:relative;\"><a href=\"#%ED%85%8C%EC%8A%A4%ED%8A%B8\" aria-label=\"테스트 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>테스트</h3>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/ba701d4b4d348f58c56eb5b5deae8057/e8950/4.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 39.24050632911392%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAICAYAAAD5nd/tAAAACXBIWXMAAAsSAAALEgHS3X78AAACWElEQVR42jWR60uTARTGX/oDojStiLzfJhZp5iWb0TBrmjppzpxOM/FWoE3NLBVvm06tvBRERSYrsy9GqaWYCZm6tOkqKxACiT50QQu3RP3gfr0IPfBwDufAj4dzhOlJM8pEFQF7gjkkjaT/2SBf5r9jefeJGfM0s5YZ3s9+JD41nfPaMiqq64mOjsHXz5/A/SFoMrLJzDqL/MRJ2tpvIrQ1NuPt4kqATwAp0lD0pcV8+DzPm6kZxkZfYzaNM/l2iuBIGTl5WuIUp3DY6sg+L28cN29BEhCEQpnO3sAIqmoaELI1abg4OxLk40lLrprORr2Ybo5xk5nBgQFGXw4zMWHiSHQshUUVHJcnkBEjp720CIU0grCQg6g1OYRFRFGnb0KQhYeya5sDwb6eGIty6bxi4MXwGEPDr+jv62V0ZASTCDwWqyA7v4j6gkJaz+Ux2NJAaXoqCvFcyepMEXiUWp0IDPT3w3W7E1KJB9VxkajjYnjSN0RXdw8dd+/RZeyi92kfEVIZh2VyDNpCSlJUdJQUECuLIiZOSWKShgPhMqprDQi+bm7scHRCIlZ/d3e8PSRcLKulpu4q1VU6brTfoefxc5x3uiAIAvkqFVkJ8Vw+cxo3dy9xtmljt9tVwoXSSoTrrTeouVRFU30DOp2eyvJyHhpvY5qyYDZbmJub5+u3HxiaW8nVZHCrqYmWa608ut9FgbZYfFIiyqRk0tKzMD7oRkDU6l8b1j+/sdlsLC8vs7S0tNGvra3xX/b1dZZ+/WRhYYHFxUUWRFutVlZWVja8urqC3W7nH9dkj8i/JDgCAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"img.png\"\n        title=\"\"\n        src=\"/static/ba701d4b4d348f58c56eb5b5deae8057/f058b/4.png\"\n        srcset=\"/static/ba701d4b4d348f58c56eb5b5deae8057/c26ae/4.png 158w,\n/static/ba701d4b4d348f58c56eb5b5deae8057/6bdcf/4.png 315w,\n/static/ba701d4b4d348f58c56eb5b5deae8057/f058b/4.png 630w,\n/static/ba701d4b4d348f58c56eb5b5deae8057/40601/4.png 945w,\n/static/ba701d4b4d348f58c56eb5b5deae8057/78612/4.png 1260w,\n/static/ba701d4b4d348f58c56eb5b5deae8057/e8950/4.png 2000w\"\n        sizes=\"(max-width: 630px) 100vw, 630px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></p>\n<p>드라마 사진으로 테스트 했을 때, 위와 같은 결과가 나왔다.\n(슬픈 표정ㅡ sadness: 0.924 / 무표정ㅡ sadness: 0.002, neutral: 0.998)</p>\n<p>'울 것 같은 얼굴'도 잘 인식하는 모습이다.</p>\n<p>실제론 사진이 아니라 카메라 캡쳐방식으로 동작할 것이므로, 얼굴을 주기적으로 찍는 코드도 한번 실행 시켜보았다.<br>\n(테스트 할만한 적절한 영상을 찾기가 어려워서... 그냥 직접 웹캠을 키고 슬픈 영상 찾아 보면서 테스트를 해봤다 ㅎ)</p>\n<p>총 71프레임이었고, matplotlib으로 나타냈을 때 다음과 같았다.</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/95e482ffdb42a58099a84cf4a52eb9a5/e8950/5.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 68.35443037974683%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAOCAYAAAAvxDzwAAAACXBIWXMAAAsTAAALEwEAmpwYAAABcUlEQVR42pWUi06DMBSGef/308TFmIhTNwYFWnql5fecAjq3RUeTUtryfzlXCtDw3kMpBWPM3VNrnaeld9amlBiFgh/WWozjiHvGNM2r0GSEmzXmTF+EEFBVFWKMdwJn4qG3aAl6aVC20Dm3wcIZeJTuNpBf6rre7HKtPJrBXQOllDm4W4G9CTiS21fAsiwxDMNmoLRjjuMVkFMuhPgTOJ3F7l/gZVJYOC3C8znGhJimX8DP7gcY4wLkouakrGWTFgWLeWgfKfgeu4PMkGGpPa7BvaDCHtNtCxMBax3w2ugsLIXBy2nASTnsjgr71uCNzp4Ois48Psnd50rh4YOSSt2yGpTLpiELhSSxNNg3Ax7fBXrt0Gkq3sHC+QBlKaudpjOHqqd2sx7WBdp79FIhrhZyzLg3u66jnqZibQU8WdyKBoH2oqmzB6JZ9ss53xtD3vQd9bL8TmCxJoKbm1duRR63Vr5nj/J3vJKGXV1/DAz8Aj1OSe6KXaGBAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"img.png\"\n        title=\"\"\n        src=\"/static/95e482ffdb42a58099a84cf4a52eb9a5/f058b/5.png\"\n        srcset=\"/static/95e482ffdb42a58099a84cf4a52eb9a5/c26ae/5.png 158w,\n/static/95e482ffdb42a58099a84cf4a52eb9a5/6bdcf/5.png 315w,\n/static/95e482ffdb42a58099a84cf4a52eb9a5/f058b/5.png 630w,\n/static/95e482ffdb42a58099a84cf4a52eb9a5/40601/5.png 945w,\n/static/95e482ffdb42a58099a84cf4a52eb9a5/78612/5.png 1260w,\n/static/95e482ffdb42a58099a84cf4a52eb9a5/e8950/5.png 2000w\"\n        sizes=\"(max-width: 630px) 100vw, 630px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></p>\n<p>▲ x축 = 프레임 번호(시간순으로 봐도 무방), y축 = sadness</p>\n<p>무표정->눈물까지 가는 데 얼마 걸리지 않은 모습이다.\n사람이 봤을 때 '슬퍼 보이는' 사진은 40부터였는데, 그래프 상에서는 차이를 확인할 수 없었다. 대신 60(=얼굴이 일그러지면서 울음이 터지는 사진)에서 반짝 하고 최고치 (0.932)를 찍었다.</p>\n<p>웹캠으로 테스트 해본 결과, 사진으로 테스트 해봤을 때 생각하지 못했던 변수가 몇가지 있었다.<br>\n<strong>순간 캡쳐라 흔들린 사진이 찍힌다는 점, 카메라 화질에 영향을 받는 점</strong> 등의 이유로 <strong>빨개진 눈 같은 특징을 가진 '울 것 같은' 얼굴이나 눈물은 인식할 수 없었고</strong>, 대신 확실하게 <strong>입꼬리가 내려가거나 얼굴이 찡그려진 순간은 포착</strong>한다는 걸 확인해 볼 수 있었다.</p>\n<h2 id=\"02-얼굴-표정-분석---캐글-데이터로-표정분석하기\" style=\"position:relative;\"><a href=\"#02-%EC%96%BC%EA%B5%B4-%ED%91%9C%EC%A0%95-%EB%B6%84%EC%84%9D---%EC%BA%90%EA%B8%80-%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%A1%9C-%ED%91%9C%EC%A0%95%EB%B6%84%EC%84%9D%ED%95%98%EA%B8%B0\" aria-label=\"02 얼굴 표정 분석   캐글 데이터로 표정분석하기 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>02. 얼굴 표정 분석 - 캐글 데이터로 표정분석하기</h2>\n<p>표정 분석방법으로는<strong>캐글 데이터를 활용해서 직접 학습시키는 방법</strong>도 있다.<br>\n1번의 Face API는 (무료 크레딧으로 해결할 수 있지만) 아무래도 비용이 나갈 수 있기 때문에 직접 학습시키는 방법도 생각해볼 수 있다.</p>\n<p>표정 분석은 얼굴 인식 - 표정 분류 두 단계로 이루어진다. \n위의 Face API가 기본적으로 얼굴인식부터 표정분류까지 학습된 모델을 다 제공한다면, 여기서는 하나하나 구성해야 한다.</p>\n<h3 id=\"얼굴-인식\" style=\"position:relative;\"><a href=\"#%EC%96%BC%EA%B5%B4-%EC%9D%B8%EC%8B%9D\" aria-label=\"얼굴 인식 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>얼굴 인식</h3>\n<p>먼저, 얼굴 인식을 위해서 opencv에서 제공하고 있는 cascade 기반으로 미리 학습된 정면 얼굴 데이터(haarcascade_frontalface_default.xml)를 사용할 수 있다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">pip install opencv<span class=\"token operator\">-</span>python</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> cv2\nface_detection <span class=\"token operator\">=</span> cv2<span class=\"token punctuation\">.</span>CascadeClassifier<span class=\"token punctuation\">(</span><span class=\"token string\">'haarcascade_frontalface_default.xml'</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p>혹은 dlib 라이브러리를 이용할 수도 있다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">pip install dlib</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> dlib\nface_detector <span class=\"token operator\">=</span> dlib<span class=\"token punctuation\">.</span>get_frontal_face_detector<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p>이런식으로 사용할 수 있다.<br>\n만약에 dlib 설치 과정에서 오류가 발생 한다면, Cmake GUI를 이용하거나 <code class=\"language-text\">pip install cmake</code>로 해결할 수 있다.</p>\n<p>그 다음으로, 얼굴 인식 성능을 높이려면 측면·명암 등의 조건을 고려했을 때에도 얼굴을 인식할 수 있도록 얼굴에 존재하는 랜드마크를 이용해야한다. 이 때에도 dlib 라이브러리를 이용해 68개의 얼굴 랜드마크로 학습된 모델을 사용할 수 있다. (<a href=\"http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2\"><strong>dlib landmarks</strong></a>)</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> dlib\npredictor <span class=\"token operator\">=</span> dlib<span class=\"token punctuation\">.</span>shape_predictor<span class=\"token punctuation\">(</span><span class=\"token string\">'shape_predictor_68_face_landmarks.dat'</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/a358b63edf6a5c6cc1d190b966bb88c1/e8950/6.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 66.45569620253164%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAANCAIAAAAmMtkJAAAACXBIWXMAAAsTAAALEwEAmpwYAAABDUlEQVR42oWSuY6EQAxE+f/PIicEiQASDgmBYLmhOWbe2qvWCuaooFWmXV0+cB43zPM8DAPneZ7btsHbth3HkfCS6VxiUuu6bpqmqqplWfq+hyDmXNf1OI63YtywwsT3/SRJuq5DH0VREATYwtG/FXONGKIVIuYhG/L0JzFKY4zNptppmmyIUm9fi/d9Vyv1SdM0z3MroP9PYuahVpCiKOg8DMOyLLVaZsnrX6ZN8WQzJ9d1Pc+L43gTcPVlVXiSdAh0ScoZ3mVPv+JTcNfb9iAodQs6PJvvPF5Bm2dzk+D+b/2JMeF/+hHgwEmpDJaxNwJC/dgJbDKPOlTFVpZ/WAWQLMtoW0uwmAUQY8wTVCT2qllPKy8AAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"img.png\"\n        title=\"\"\n        src=\"/static/a358b63edf6a5c6cc1d190b966bb88c1/f058b/6.png\"\n        srcset=\"/static/a358b63edf6a5c6cc1d190b966bb88c1/c26ae/6.png 158w,\n/static/a358b63edf6a5c6cc1d190b966bb88c1/6bdcf/6.png 315w,\n/static/a358b63edf6a5c6cc1d190b966bb88c1/f058b/6.png 630w,\n/static/a358b63edf6a5c6cc1d190b966bb88c1/40601/6.png 945w,\n/static/a358b63edf6a5c6cc1d190b966bb88c1/78612/6.png 1260w,\n/static/a358b63edf6a5c6cc1d190b966bb88c1/e8950/6.png 2000w\"\n        sizes=\"(max-width: 630px) 100vw, 630px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></p>\n<h3 id=\"표정-분류\" style=\"position:relative;\"><a href=\"#%ED%91%9C%EC%A0%95-%EB%B6%84%EB%A5%98\" aria-label=\"표정 분류 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>표정 분류</h3>\n<p>본격적으로 표정분류를 하기위해 사용할 데이터는 <a href=\"https://www.kaggle.com/msambare/fer2013\"><strong>캐글 FER-2013 Faces atabase</strong></a>이다.</p>\n<p>28,709개의 example이 있으며, 표정 분류는 Angry, Disgust, Fear, Happy, Sad, Surprise, Neutral 로 되어있다.</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/2f098ee772a774a3f90504639584249c/e8950/7.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 17.088607594936708%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAADCAYAAACTWi8uAAAACXBIWXMAAAsTAAALEwEAmpwYAAAAv0lEQVR42h2OvQpAABhFvbAnQCmbQmQxSCKDDIqB5LckFvJTShlM3uLKt9zhdm/nMM/zIMsyVFUFwzAgyzL6vkdRFBiGAWVZom1bjOOIOI6hKAokSYJt27AsC8dx4L5v2m7bBuYPlmXhui54noeu62iaBr7vwzRNOI4DQRDAcRyCIIDneRBFEaqqQtM0gp/nSdCu68C874s0TbHvO9nUdU3UaZowzzMdwjBEkiRk8Xd5ntM2iiKCX9eFdV2xLAs+FAS6cNvuqsUAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"img.png\"\n        title=\"\"\n        src=\"/static/2f098ee772a774a3f90504639584249c/f058b/7.png\"\n        srcset=\"/static/2f098ee772a774a3f90504639584249c/c26ae/7.png 158w,\n/static/2f098ee772a774a3f90504639584249c/6bdcf/7.png 315w,\n/static/2f098ee772a774a3f90504639584249c/f058b/7.png 630w,\n/static/2f098ee772a774a3f90504639584249c/40601/7.png 945w,\n/static/2f098ee772a774a3f90504639584249c/78612/7.png 1260w,\n/static/2f098ee772a774a3f90504639584249c/e8950/7.png 2000w\"\n        sizes=\"(max-width: 630px) 100vw, 630px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span>\n▲ Angry, Disgust, Fear, Happy, Neutral, Sad, Surprise</p>\n<p>대충 각 분류에서 하나씩 출력해보자면 이런 이미지의 데이터셋인데, 벌써부터 Surprise나 Angry에서 오분류의 느낌이 느껴진다 ^^;..</p>\n<h3 id=\"사진-표정-분석-테스트\" style=\"position:relative;\"><a href=\"#%EC%82%AC%EC%A7%84-%ED%91%9C%EC%A0%95-%EB%B6%84%EC%84%9D-%ED%85%8C%EC%8A%A4%ED%8A%B8\" aria-label=\"사진 표정 분석 테스트 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>사진 표정 분석 테스트</h3>\n<p>위의 데이터를 사용해서 Keras로 CNN을 구현하여 모델을 학습시켰다.</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/4eca6af66ae6636be82834ea69c59a76/e8950/8.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 84.17721518987341%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAARCAYAAADdRIy+AAAACXBIWXMAAAsTAAALEwEAmpwYAAAB6ElEQVR42pXU104rQRAE0P3/f0MiiBxsTM4YjAPBBWdHLfzAw70rtcY73V1TVT3rbjhM7u6Sx8fk5CS5vEyen9M/y2WLj4/k87OtX1+/+8K7nPDeDQbJ8XGys9MAHx7aAbe3bXXA1lZyeJisrbX1/j65uWnraNTy+tV3p6fJ/n5i3dtLzs6S2Sx5e0um0+Tl5XdfXF0lVF1ft5qnp2R9vYGp7wExU3R0lGBcB2BjPThIzs8boFU9gPf3Bsii+bxFh7oCHqIPlOxi+fraLAGAlXrAavgGbHe3yedxD4hFSbm4aA2agdSBPFVjX15usWgM7bOmZyhZ0rDDUlSzkPdee2xxEABMEaGQqk4z001TI780lTdWkngHRF1ZhCFA+WLcSyZTIZZlAQDAZUVdp7oudfcmk8bUfew95A0JQLH1mx9OU6gBa3WUqJMzLEOrg8bjlWuDDf8wqfsHqKZcHqplg7wcz1jimplFL7muClCN/FGkSQDUsOpdXakCpEhtPxRgwuk+ISsQEgRJGxttH4vVYQHi8+Zmq9P38y0vf6Qu+8vLPyxMTTNAzTzSAKQOsm/F2KC8N8Bhk4QdILJ96NvbbZr/+3SjwfRHzqKfHh95VV8CSbyqAf0VchX9lOeTcWZ+/fGs/u/9a3wDnJ8WResTnE0AAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"img.png\"\n        title=\"\"\n        src=\"/static/4eca6af66ae6636be82834ea69c59a76/f058b/8.png\"\n        srcset=\"/static/4eca6af66ae6636be82834ea69c59a76/c26ae/8.png 158w,\n/static/4eca6af66ae6636be82834ea69c59a76/6bdcf/8.png 315w,\n/static/4eca6af66ae6636be82834ea69c59a76/f058b/8.png 630w,\n/static/4eca6af66ae6636be82834ea69c59a76/40601/8.png 945w,\n/static/4eca6af66ae6636be82834ea69c59a76/78612/8.png 1260w,\n/static/4eca6af66ae6636be82834ea69c59a76/e8950/8.png 2000w\"\n        sizes=\"(max-width: 630px) 100vw, 630px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span>\n<span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/f1e2c1eaf0039aa2ef9bcd2ff137f90f/e8950/9.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 114.55696202531647%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAXCAYAAAALHW+jAAAACXBIWXMAAAsTAAALEwEAmpwYAAAD20lEQVR42k2V2U9TXRTF+zea+KY4xDmaaBxi4qyIE4ooKqMypERAiahoBI3P+qDROFBxglBaKmClfhdbeu76zu9sL/iwc07P2WetvfZwm5qf/6FcLqfc9IyyU3ktlCLFTnIu1tJS/Hd1qlbjYHHMncJaqVT93un375K/q2pxMVJq4deMij/zKi0U9KuY1/z8tOZmp1Uo5PSjkNX83KzyuUkVi7MqzEyrXC57sIoHqIS1XK5ocrKiiYmKSqWyUm1tS2pocOrpcerrcxoYqHpbUkdHVTdvOnV2VpVOr+wbG2O/xmpvj/1ZrAsXYtXUxFq1SnrxoqRUV5fTvXvS6IjU2irt3i3t3SsdPiydPi21tNh5W6utly5JFy9K165JV6+a4XPunPTt2x8DxKGhwQ537jTA69elJ0+k4WED3r/fSE6dko/KwNvb5aOUmpul8+elTGZRqd5eFxi4uHVLamry0bRJV65YFJcvS0eOSNu2GWBfn/T8uXTnjnT0qHTokK21tdKHDx5weNiFaBobDYQoz5yxPcCtf6Vyn0iGFFX79klbtkjHjxvB1JQHHBlx4fHmzXYJY0eHRUt+uCNKSOrqDAiJN26sALMnZV++eMCWFhccCZtHON29a9KIYP16IyJvkBB1QkS0vDl71gA/f/aAg4MuMOCA4VBfb9Gwh4gHnZ3S/fsGSuHWrZO2bzdwFGGhKE1NLkRy7NgKGJcAUKikPYiQKCCiohSKVHR3S0NDJvv1aw9YV+e0caMV48ED6fFjk0VkVJXqAYK8nh6LEEKISM+/REEyE4JUKo0RzYkTljeMKB4+NLk85g4jDfQk/hCh5tMnD3j7tgsScE6qRRUBYoWEiDknNWvW2DSl09b4g4OWguU+rK93YRJgovMxJNF3kJAKQFHBeTIlkLMCRnHWrpXevPGA/f0uyHn61GaSidixw/qRAiURQgQAkQLCSh655xyir189YHe3Cw8T2ciigjg9emQVpDhbt0p79ljeAEMRKcEPYHI6NuYB+SwhJ2kTpCIn+WAkPQkYbdXfLz17Zs1/4ICdHzxoqfn40QOOjrrlkHlMPgHAaAvyxj1FIhKUsMef1tq1y85Qks16wKEh+3xt2KDQjww6Y4fRezBjJ0+aXAhRQF7JXzLbnI+P/zHJiSwk4tzbK3V1WT5raqwfeTwwYJMBEW/IG0C1tXHYj4/7/5R02i1/slhpWpwwfiezDBENjGw6YfVqadMmf97MeRxS8+rVnFKZzH96+zbSu3crlslE+v498m0Q6f37yCc78nNqd6xjY5Fevoz8qEWanCj6P6i89yn6+6z+B8K6ymg1Nsr1AAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"img.png\"\n        title=\"\"\n        src=\"/static/f1e2c1eaf0039aa2ef9bcd2ff137f90f/f058b/9.png\"\n        srcset=\"/static/f1e2c1eaf0039aa2ef9bcd2ff137f90f/c26ae/9.png 158w,\n/static/f1e2c1eaf0039aa2ef9bcd2ff137f90f/6bdcf/9.png 315w,\n/static/f1e2c1eaf0039aa2ef9bcd2ff137f90f/f058b/9.png 630w,\n/static/f1e2c1eaf0039aa2ef9bcd2ff137f90f/40601/9.png 945w,\n/static/f1e2c1eaf0039aa2ef9bcd2ff137f90f/78612/9.png 1260w,\n/static/f1e2c1eaf0039aa2ef9bcd2ff137f90f/e8950/9.png 2000w\"\n        sizes=\"(max-width: 630px) 100vw, 630px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span>\n▲ 모델 요약 및 학습 진행 화면(4시간 소요)</p>\n<p>Face API를 테스트하기 위해 썼던 드라마 사진으로 똑같이 테스트를 해보았다.</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/f618dc0ba7d6b2657230ce3031aa2fa4/e8950/10.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 72.15189873417721%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAOCAYAAAAvxDzwAAAACXBIWXMAAAsSAAALEgHS3X78AAAD2ElEQVR42iXT/1MTdBzH8f0JJcp3tjHly2DIhIHIF/li4GkFdmfo1Q/BVXZemKGlknXmWVp+Ib5UglpiX0yNMdh2i2+DARtjGxsMxkYu5azrB0sgw+uAfnj2Yf3wvvt87nOfx71fny+SwLSPYHAO3R0d2/OLyc7OIytrGypVCgV5uVxpaQ2t+2fnCNz9DX/gPpNeP273JJOeCSbHXXg9Hma8U9wL3kPisTtwWMco37kbhSyReLkSRXwaclkKkZHRJMiltLV9w+wvv+P13cczMY3DOYHTNYXL4cI+PMT42JiAx7kbCCAJeH189cVltiiVZKkzUKvUJCWoUChSqdq1g4O7C3mhogJfYI6pmTnG10CXJ4SOWkexWcwCtON1u/jZ70MSnA1y+I0DJIlO0pXJZCRuIj0+nr252Yycr0P7Xg3HXnkJ95iIFXiA0zOFze5idNTFsGUIS18vjlEbbqeT2bUOpye9lOXnCVBGYryMdAEnyOKoyNdw/Wg1teUlnH63Fq+IODUdxOH2YrW5QtXT3c1PBj3DA2YcNhv+6Wkkhju3UQlMqZAjjY5EFReDNCqcMnUKpgunOPniszR+9CFuhxen04fdMcGI1cHA4Ahdug6MnVrMvT2MWW3MzviRnKk7gSIinJSNa2AEyQKN2RDGuVdfxtPWgv7j9zG0XaW/ZxBz3xD9Fgf9A1a6u/swdnViMhgYELHtVisB3wyS/XvKkUeGkyyixsdGkRoTTVz4Oi69VsmN1/dRV17EibffFJtNGAzdGHuG6DJ209VlwKDXYxRgn4g+OjyM3yc6fH5nGdLwDSRKY5HHCFBEVkSHc3pfKS2Vz3GgNI+tORrxTjsE1IPO2IuuU097uxatth2dVsTWG7D0DzDhnkBSWlwSAhNio8XZRYTAhPVPU1Okprm6nOK0RGRhT9Ha0EyXaZDvb+u59vVNmptbafisiUsXG6m/2ERj/efc+uFHJDtLSogJW4dcYHER60M3vNZt5iYp0hiBb1SyWammqvogjV9+y8kPznPk6CkOv1XHkdrjHHunjrNnLtBQ30KH1oCkan8Fsqg4VEmpYuNmNOoctmny2VW4gy3qPDSZhWgyCsjOzOF43Vk+vdTCuU/qaWq6zLWr17n53S2MxgGGRsQ39AaR1B6qYaumiJLCXRQVlLE9r5TtuUVU7hFgehpJiSmkJqsofyadE4f2cuPmbbRGszjPPgxGEyZTD2azHUsIvItkaWmJhYVFFhf+ErUYGi/Mz/P48Tzz83/w8OGfWK2P+PXBIsv/POLJk79ZWV1leXlF1DIrKyui/p+vrv7LfxVM1T7qi3BTAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"img.png\"\n        title=\"\"\n        src=\"/static/f618dc0ba7d6b2657230ce3031aa2fa4/f058b/10.png\"\n        srcset=\"/static/f618dc0ba7d6b2657230ce3031aa2fa4/c26ae/10.png 158w,\n/static/f618dc0ba7d6b2657230ce3031aa2fa4/6bdcf/10.png 315w,\n/static/f618dc0ba7d6b2657230ce3031aa2fa4/f058b/10.png 630w,\n/static/f618dc0ba7d6b2657230ce3031aa2fa4/40601/10.png 945w,\n/static/f618dc0ba7d6b2657230ce3031aa2fa4/78612/10.png 1260w,\n/static/f618dc0ba7d6b2657230ce3031aa2fa4/e8950/10.png 2000w\"\n        sizes=\"(max-width: 630px) 100vw, 630px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span>\n<span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/eae40cdbdd7cdfa82c0ed489033846d7/e8950/13.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 74.0506329113924%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAPCAYAAADkmO9VAAAACXBIWXMAAAsSAAALEgHS3X78AAADtElEQVR42oWT60/bVRjHf3PAyn1unaAg21gZtzJKoUCh7a83WkpppbT0RsutXAVGq5RL6YYs06QZ8UICGDaNyYKKhr3Q+Mr3/h+a/Q3z5cdDZ0x8tZM8OeckTz7n+zzP90jOyRmaNJ2Mjo2zktxk6f46H66lWVhKodPpUd6o4roIpVLsymr6jVbGwpN4RkK4PQEcrhEsdjcmsxO9wYpkCkSob2oVSVMsrqSZW0yxuJymu8dIeXkFFRVXKSu/SrnYS0rFvfIadqdXAKMC5sc64MUgu+jps9PZLQugL0iDAE4nlllZ22Y1mSE2Mc/NW3dQvlNN7Xu1NNbfoVnEu9W1KIrLULd1EozMMPxBWEBHhUIP/SYn3foLhd5RVA3NLAl1q8lt1jc/wWJzcbOmjtt19YzKMnZtJ06tFk1DE6WKUurEYxfAEX+MIU+QgUEfRvOFShtSv9ONurWd1VQmH+tbe9zr0KEouoLTYGQ9HmPR5yXmGsTY0UFlcQkq1V1C0SnR9wlReiSv0mQZ+hdod9Gt62Pt4yzLa1tiMNs4nB5MYlDPdtY5/yLH6eMsBxspslMxjC3NyCYLkXgiD/T6ogy6A8g2N739dqQ+sx1Dv0X0bys/kLmFNZ7tPuBgZoZPJ2P8cXrCWW6P89wjDjfWMGq0+PwRouNTBIKx/4Bm2/BrYK9BRpYHmF1IEY7Pk1xY5vuHGdJjIXbGI5x/tsvzj5L8uv+Y6WEXndoeJiZmCYbjjAai+ZKdQ35kq/v1ULp69FitLqZn7+OPJNhPb/D74ecE7E7GrBZ+yKY5SyX5amUOv9tLNDRJbHxGqLsod/x/Q8nbRtPZTZfOICS76dLLOMw2fjs+YD8lHujRcZxO8sv+I7ITYRpUTThsg3hHgvhF/0b88fxALsrVGwbQ6kxIjc1qCoqKUZSUUyg8dkXE1w+zHGW2sGk0JP0+nm6myKwuU1J5nQJhm8prN7hV30ibpluY2iliEF2vhXZtP1KzuiMPKRW/4XJRKS13m/j5SY75cJREfJIZs8xeYppsZocq4c3iskpKK99GIX7NhZD6hhb6jA46uoyo23uRPKFp3lepRZISSZJIeDwcb27QKkyc3siwMhZkYy7Bg4e7VFXX5HMuvVWAdLlQnC9RWKQQ0DZuq+5RU9eIdPrTC3JfHrGS2iIaneDbJ/s8zeWIRmKcnHzDj2cvODr8jqPj50Si01jtDhyDbtG7IQYcLuz2AcZCUeJTc4THJ5F4w3r1N/z5F7x8Kc6veOP6B/jjXIrH9UWkAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"img.png\"\n        title=\"\"\n        src=\"/static/eae40cdbdd7cdfa82c0ed489033846d7/f058b/13.png\"\n        srcset=\"/static/eae40cdbdd7cdfa82c0ed489033846d7/c26ae/13.png 158w,\n/static/eae40cdbdd7cdfa82c0ed489033846d7/6bdcf/13.png 315w,\n/static/eae40cdbdd7cdfa82c0ed489033846d7/f058b/13.png 630w,\n/static/eae40cdbdd7cdfa82c0ed489033846d7/40601/13.png 945w,\n/static/eae40cdbdd7cdfa82c0ed489033846d7/78612/13.png 1260w,\n/static/eae40cdbdd7cdfa82c0ed489033846d7/e8950/13.png 2000w\"\n        sizes=\"(max-width: 630px) 100vw, 630px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></p>\n<p>각각 sadness와 neutral이 0.9를 넘는 높은 수치로 나왔던 Face API와 비교했을 때, 슬픈 표정의 예시로 사용한 왼쪽 사진의 감정을 fear로 다르게 인식한 것을 확인할 수 있었다.</p>\n<p>이 데이터셋을 사용한 여러가지 모델을 찾아보았을 때, 대략 정확도가 50%~70%정도로 나오는걸 알 수 있었다. 때문에 일부 데이터가 오분류 되어 있는게 정확도가 낮은 원인이 아닐까 생각된다.<br>\n같은 데이터셋을 사용한 Kaggle 챌린지 best score의 상위권에 랭크한 코드 역시 test accuracy가 50% 정도로 나온 걸 확인할 수 있었다.</p>\n<h3 id=\"실시간-영상-분석-테스트\" style=\"position:relative;\"><a href=\"#%EC%8B%A4%EC%8B%9C%EA%B0%84-%EC%98%81%EC%83%81-%EB%B6%84%EC%84%9D-%ED%85%8C%EC%8A%A4%ED%8A%B8\" aria-label=\"실시간 영상 분석 테스트 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>실시간 영상 분석 테스트</h3>\n<p>openCV를 활용하여 실시간 영상 표정 분석을 하는 코드도 실행을 시켜보았다. <a href=\"https://m.blog.naver.com/roboholic84/221633210887\"><strong>다음 링크</strong></a>의 코드를 참고했다.</p>\n<p>같은 캐글 데이터를 사용하지만 다른 구조를 갖고있는 모델을 사용했다.</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/6c0fb4b2a48d9ac9bb783074d13bd8d6/e8950/11.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 136.0759493670886%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAbCAYAAAB836/YAAAACXBIWXMAAAsTAAALEwEAmpwYAAACcElEQVR42pXVCW8iMQwF4Pn/v64SFFTaQqH05D5aoFdWnyWPWER3YaQoGU/8/J7tZKpy5Pn+/i4vLy9lMpmU0WhUBoNBub+/jzXb09NT+fr6OuZaqmPGz8/PcFqv12WxWJSrq6sY8/k8bI+Pj7HnZEDP6+tr6ff74dztdsvl5WV5fn4Om2A/Pz+nA358fIQzR2B3d3dlOByWm5ubCMBuz8mAossXEADX19el2WzGmk2wsxjKj6JsNpvImaIAXS6XYfsvQ9FyeFRwPB6X2WwWAzNy811+z6pytg4n8/v7ezBO9my/PZUN8pXyjLe3twAxttttsMo9BrvZPsNae7FXWDCm9JSM0XQ6rfPX6XRiZpMCcypJ5jVgRsVC85q1izzKV6/Xi7VCCGq/90MSiIXk3W4XjmiTh4kG1iK+qSrp+32aDPcBa4ZAgXEUWSNfXFzUDEkEAlSA1WpVHz9s2WtAElHN9nD45e/h4SGkAxTILICR39nsyRYDXomclVYAMwezAE4FZ6AYcCQXkUwThtbYh2QGp4AzhgBcBlkgAbKhzd7dPtaZFmmAE4CQOe87ArUZIHZUKAAnDBUsi8H+V1HI5syRBCwnk2nYBAIO0F578l48PFmRQ5t8BCJn2JEOrNVqlXa7HWwws8+3ZCZIDt/JrrKv8ijlccv7T64Uy7tZf97e3tY5y+NowKmO3YUeDDEiT86yndh8k/eTbpsEzCOHmWPYaDQil1iy7/9T9q+/fzLMnKZ8+cPS+8k/qUPJ+tPIwsmVVjpbMifSyDSTrGWwU5izbmw9RapiaHQ/eTdQ/gLOkpyAJGcbyRtQskn2/hvgH/cUH8K4bk1MAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"img.png\"\n        title=\"\"\n        src=\"/static/6c0fb4b2a48d9ac9bb783074d13bd8d6/f058b/11.png\"\n        srcset=\"/static/6c0fb4b2a48d9ac9bb783074d13bd8d6/c26ae/11.png 158w,\n/static/6c0fb4b2a48d9ac9bb783074d13bd8d6/6bdcf/11.png 315w,\n/static/6c0fb4b2a48d9ac9bb783074d13bd8d6/f058b/11.png 630w,\n/static/6c0fb4b2a48d9ac9bb783074d13bd8d6/40601/11.png 945w,\n/static/6c0fb4b2a48d9ac9bb783074d13bd8d6/78612/11.png 1260w,\n/static/6c0fb4b2a48d9ac9bb783074d13bd8d6/e8950/11.png 2000w\"\n        sizes=\"(max-width: 630px) 100vw, 630px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span>\n<span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/fad64162140a6b0e4ac326e97c8f631b/e8950/12.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 55.69620253164557%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAYAAAB/Ca1DAAAACXBIWXMAAAsSAAALEgHS3X78AAACM0lEQVR42p2TS0iUURSAfwdnYzs3iisJLXURtMqdmxAMgtCFklA+ygiaicBQocAeGBShoIZStBAM04IMitGUVOxhKoU/06Sp40zpzOg8nLcz/vN/3fkXGhW9LhzuPffc85177jlX4h+Hqqq/tUvx7W02N/2EgiEURSEejxOPxcQcIxKJEN3aYiupi3N/MySX28e0PI/N6WbV42fOLNPTc5+OO+10dnUyaBpB/mzD5RNB3W6sZjNLVisWi0UTWZZxOp07t5c8/iAW6xoObwhfXGVsyMSVulqMp2q41nyZ4YnXLKw4CQiHmbY2itPTyS4oYE9aGnq9HkmSMBqNGjCZoeQLhFl2eNgIRAkoKk/7+7h+/gytDQZuNF5k/N0sKw4vyYQH2tvJz93HocJC0gRQp9NpQIPBsAv0BsPMf11nzetnPRxBnhrHdLuJJy31dN+8ysibGRaFPSocRltbOZiZyd68PA2kT039GbixGWT6k5WFVRejbz/wqPchH3tv0XWhmqrjlQy+GOP9oh2PAi9FykVZWWTn5qJLSSH1V0D7motnE1OYJmeorquntLSKS4azHCspZn/+AZqaWxh6NYtVFGyyu5u7OTkMFBXRl5HBYfGeSWBjQ8MucNH2hcfDY3Tce0B5+Ulqas5RUVlLWVkFJUeOcqL2NP3PR5hbWEIJhwjb7UQdDmI2G+tClkXFvV7vbtskS51IJNgWfZaMoIi1qia0PU3XJPHHht4B/s9P+VG+B34D2jbTRuplg0AAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"img.png\"\n        title=\"\"\n        src=\"/static/fad64162140a6b0e4ac326e97c8f631b/f058b/12.png\"\n        srcset=\"/static/fad64162140a6b0e4ac326e97c8f631b/c26ae/12.png 158w,\n/static/fad64162140a6b0e4ac326e97c8f631b/6bdcf/12.png 315w,\n/static/fad64162140a6b0e4ac326e97c8f631b/f058b/12.png 630w,\n/static/fad64162140a6b0e4ac326e97c8f631b/40601/12.png 945w,\n/static/fad64162140a6b0e4ac326e97c8f631b/78612/12.png 1260w,\n/static/fad64162140a6b0e4ac326e97c8f631b/e8950/12.png 2000w\"\n        sizes=\"(max-width: 630px) 100vw, 630px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></p>\n<p>▲ 신경망 구조 및 실행화면(얼굴을 한껏 찌푸린 상태)</p>\n<p>역시나 웹캠을 키고 직접 테스트해본 결과, 얼굴 일그러짐에 따른 Sadness는 잘 인식했던 Face API에 반해 Neutral로 오판하는 것을 확인할 수 있었다.</p>\n<h2 id=\"04-마무리\" style=\"position:relative;\"><a href=\"#04-%EB%A7%88%EB%AC%B4%EB%A6%AC\" aria-label=\"04 마무리 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>04 마무리</h2>\n<p>지금까지 프로젝트 간단 설명, Microsoft Azure Face API, 캐글데이터를 사용한 표정인식 방법을 알아보았다.</p>\n<p>정리하자면 Face API와, 캐글 데이터를 사용하여 직접 학습시킨 모델을 각각 테스트 한 다음 비교해본 결과 <strong>최종적으로 Microsoft azure의 Face API</strong>가 우리 팀의 프로젝트의 표정 분석 파트의 기술로 채택되었다.</p>\n<p>Face API의 경우에는 API라 얼굴 인식 자체의 정확도는 높일 수 없지만 감정 추출 주기를 조정하거나, 만약 단순 분류가 아니라 수치를 이용한다면 그 기준점 등을 조정해보면서 얼굴을 더 잘 인식할 수 있는 방법을 찾아볼 예정이다.</p>\n<h2 id=\"05-참고자료\" style=\"position:relative;\"><a href=\"#05-%EC%B0%B8%EA%B3%A0%EC%9E%90%EB%A3%8C\" aria-label=\"05 참고자료 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>05 참고자료</h2>\n<ul>\n<li><a href=\"https://www.kaggle.com/dencho143/face-emotion-classification-with-mlp-2-barykin\">https://www.kaggle.com/dencho143/face-emotion-classification-with-mlp-2-barykin</a></li>\n<li><a href=\"https://github.com/sunsmiling/facial-emotion-detector\">https://github.com/sunsmiling/facial-emotion-detector</a></li>\n<li><a href=\"https://github.com/SeoJinHyuk14/facialExpression\">https://github.com/SeoJinHyuk14/facialExpression</a></li>\n<li><a href=\"https://m.blog.naver.com/roboholic84/221633210887\">https://m.blog.naver.com/roboholic84/221633210887</a></li>\n<li><a href=\"https://electronicprogrammers.com/44\">https://electronicprogrammers.com/44</a></li>\n<li><a href=\"https://github.com/dinuduke/Facial-Emotion-Recognition\">https://github.com/dinuduke/Facial-Emotion-Recognition</a></li>\n</ul>","tableOfContents":"<ul>\n<li>\n<p><a href=\"#01-%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8-%EC%84%A4%EB%AA%85\">01 프로젝트 설명</a></p>\n</li>\n<li>\n<p><a href=\"#02-%EC%96%BC%EA%B5%B4-%ED%91%9C%EC%A0%95-%EB%B6%84%EC%84%9D---%EC%99%B8%EB%B6%80-%EC%84%9C%EB%B9%84%EC%8A%A4%EC%97%90%EC%84%9C-%EC%A0%9C%EA%B3%B5%ED%95%B4%EC%A3%BC%EB%8A%94-face-api-%EC%82%AC%EC%9A%A9%ED%95%98%EA%B8%B0\">02. 얼굴 표정 분석 - 외부 서비스에서 제공해주는 Face API 사용하기</a></p>\n<ul>\n<li><a href=\"#api-%EC%82%AC%EC%9A%A9%EC%9D%84-%EC%9C%84%ED%95%9C-%EA%B0%84%EB%8B%A8%ED%95%9C-%EC%82%AC%EC%A0%84-%EC%A0%88%EC%B0%A8\">API 사용을 위한 간단한 사전 절차</a></li>\n<li><a href=\"#%EC%BD%94%EB%93%9C\">코드</a></li>\n<li><a href=\"#%ED%85%8C%EC%8A%A4%ED%8A%B8\">테스트</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#02-%EC%96%BC%EA%B5%B4-%ED%91%9C%EC%A0%95-%EB%B6%84%EC%84%9D---%EC%BA%90%EA%B8%80-%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%A1%9C-%ED%91%9C%EC%A0%95%EB%B6%84%EC%84%9D%ED%95%98%EA%B8%B0\">02. 얼굴 표정 분석 - 캐글 데이터로 표정분석하기</a></p>\n<ul>\n<li><a href=\"#%EC%96%BC%EA%B5%B4-%EC%9D%B8%EC%8B%9D\">얼굴 인식</a></li>\n<li><a href=\"#%ED%91%9C%EC%A0%95-%EB%B6%84%EB%A5%98\">표정 분류</a></li>\n<li><a href=\"#%EC%82%AC%EC%A7%84-%ED%91%9C%EC%A0%95-%EB%B6%84%EC%84%9D-%ED%85%8C%EC%8A%A4%ED%8A%B8\">사진 표정 분석 테스트</a></li>\n<li><a href=\"#%EC%8B%A4%EC%8B%9C%EA%B0%84-%EC%98%81%EC%83%81-%EB%B6%84%EC%84%9D-%ED%85%8C%EC%8A%A4%ED%8A%B8\">실시간 영상 분석 테스트</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#04-%EB%A7%88%EB%AC%B4%EB%A6%AC\">04 마무리</a></p>\n</li>\n<li>\n<p><a href=\"#05-%EC%B0%B8%EA%B3%A0%EC%9E%90%EB%A3%8C\">05 참고자료</a></p>\n</li>\n</ul>","frontmatter":{"title":"[감정인식 챗봇 스피커 '버디' 프로젝트] 얼굴 표정 인식 파트","date":"2021.05.26","description":"[감정인식 챗봇 스피커 '버디' 프로젝트]의 얼굴 표정 인식 파트 구현 내용","category":"Project","tag":["project","딥러닝"]}},"previous":null,"next":{"fields":{"slug":"/Project/[2021-11-11][패션_정보_웹]_쇼핑몰_크롤링/"},"frontmatter":{"title":"[패션 정보 웹 프로젝트] 쇼핑몰 크롤링"}}},"pageContext":{"id":"04d510f2-b08c-5af6-a737-260d9f24c926","previousPostId":null,"nextPostId":"384ae3cd-a12f-595d-ace5-5056984e49a2"}},"staticQueryHashes":["2841359383"],"slicesMap":{}}